import os
import streamlit as st
import streamlit.components.v1 as components
import openai
import base64
import backoff
import tiktoken
import time
import pandas as pd
import matplotlib.pyplot as plt
import feedparser
import requests
from datetime import datetime, date
from urllib.parse import urlencode, quote_plus
from dotenv import load_dotenv
from llama_index.core import (
    VectorStoreIndex, SimpleDirectoryReader,
    StorageContext, load_index_from_storage, Settings
)
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
import logging, traceback
from io import BytesIO
from PIL import Image

load_dotenv()

# â”€â”€â”€ API í‚¤ë“¤ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai.api_key = (
    st.secrets.get("OPENAI_API_KEY")
    or os.getenv("OPENAI_API_KEY", "")
)
API_KEY      = os.getenv("ODCLOUD_API_KEY")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
HF_API_URL   = os.getenv("HF_API_URL")

# â”€â”€â”€ 1) ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ (Google News RSS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=300)
def fetch_google_news(keyword: str, max_items: int = 10):
    clean_kw = " ".join(keyword.strip().split())
    params   = {"q": clean_kw, "hl": "ko", "gl": "KR", "ceid": "KR:ko"}
    rss_url  = "https://news.google.com/rss/search?" + urlencode(params, doseq=True)
    feed     = feedparser.parse(rss_url)
    items    = []
    for entry in feed.entries[:max_items]:
        pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        source   = entry.get("source", {}).get("title", "")
        items.append({
            "title":  entry.title,
            "link":   entry.link,
            "source": source,
            "date":   pub_date,
        })
    return items


def google_news_section():
    st.subheader("ğŸ“° Google News ê²€ìƒ‰")
    kw        = st.text_input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” | ê²€ìƒ‰ í›„ ë§í¬ ë³µì‚¬ ê¸°ëŠ¥ì„ í™œìš©í•˜ì„¸ìš” ! ", value="ê¸€ë¡œë²Œ ESG í˜„í™©")
    max_items = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ê°œìˆ˜", 5, 100, 10)

    if st.button("ë³´ê¸°", key="news_btn"):
        news = fetch_google_news(kw, max_items)
        if not news:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # â‘  ê²°ê³¼ ëª©ë¡ (í™”ë©´ìš©)
        for it in news:
            st.markdown(
                f"- **[{it['source']}] Â· {it['date']}** "
                f"[{it['title']}]({it['link']})",
                unsafe_allow_html=True
            )

        # â‘¡ â€œë²ˆí˜¸. ì œëª© | ë§í¬â€ í˜•ì‹ìœ¼ë¡œ ë¬¸ìì—´ ìƒì„±
        links_str = "\n".join(
            f"{i+1}. {n['title']} | {n['link']}"
            for i, n in enumerate(news)
        )
        # ìŠ¬ë˜ì‹œë¡œ ì´ì–´ë¶™ì´ê³  ì‹¶ë‹¤ë©´:
        # links_str = links_str.replace("\n", " / ")

        # â‘¢ ìˆ¨ì€ textarea + ë³µì‚¬ ë²„íŠ¼
        components.html(
            f"""
            <textarea id="linksArea" style="opacity:0;position:absolute;left:-9999px;">
{links_str}
            </textarea>
            <button id="copyBtn"
                    style="margin-top:8px;padding:6px 12px;
                           background:#f44336;color:#fff;border:none;border-radius:4px;
                           cursor:pointer;font-weight:bold;">
                ğŸ“‹ {len(news)}ê°œ ë§í¬ ë³µì‚¬
            </button>
            <script>
            const btn  = document.getElementById("copyBtn");
            const area = document.getElementById("linksArea");
            btn.onclick = () => {{
                area.select();
                document.execCommand("copy");
                const old = btn.innerText;
                btn.innerText = "âœ… ë³µì‚¬ ì™„ë£Œ!";
                setTimeout(()=>btn.innerText = old, 1500);
            }};
            </script>
            """,
            height=50,
        )

        # â‘£ ë¯¸ë¦¬ë³´ê¸°(ì„ íƒ)
        st.text_area("ğŸ”— ë§í¬ ë¯¸ë¦¬ë³´ê¸°", links_str, height=120)
# â”€â”€â”€ 2) ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vessel_monitoring_section():
    st.subheader("ğŸš¢ í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ")
    date_from = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", date.today())
    date_to   = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", date.today())
    page      = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", 1, 1000, 1)
    per_page  = st.slider("í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê±´ìˆ˜", 1, 1000, 100)
    if st.button("ğŸ” ì¡°íšŒ"):
        params = {
            "serviceKey": API_KEY,
            "page":       page,
            "perPage":    per_page,
            "fromDate":   date_from.strftime("%Y-%m-%d"),
            "toDate":     date_to.strftime("%Y-%m-%d"),
        }
        with st.spinner("ì¡°íšŒ ì¤‘â€¦"):
            res = requests.get(
                "https://api.odcloud.kr/api/15128156/v1/uddi:fdcdb0d1-0296-4c3b-8087-8ab4bd4d5123",
                params=params
            )
        if res.status_code != 200:
            st.error(f"API ì˜¤ë¥˜ {res.status_code}")
            return
        data = res.json().get("data", [])
        if data:
            df = pd.DataFrame(data)
            st.success(f"ì´ {len(df)} ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€ 3) ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def today_weather_section():
    st.subheader("â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì¡°íšŒ")
    city_name = st.text_input("ë„ì‹œ ì´ë¦„ ì…ë ¥ (ì˜ˆ: ì¸ì²œ,ì¸ì²œê´‘ì—­ì‹œ, Busan)")
    if st.button("ğŸ” ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°"):
        if not city_name:
            st.warning("ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return

        q_name  = quote_plus(city_name)
        geo_url = f"https://geocoding-api.open-meteo.com/v1/search?name={q_name}&count=5&language=ko"
        with st.spinner("ìœ„ì¹˜ ê²€ìƒ‰ ì¤‘â€¦"):
            geo_res = requests.get(geo_url)
        if geo_res.status_code != 200:
            st.error("ì§€ì˜¤ì½”ë”© API ì˜¤ë¥˜")
            return
        results = geo_res.json().get("results")
        if not results:
            st.warning("ë„ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        loc          = results[0]
        lat, lon     = loc["latitude"], loc["longitude"]
        display_name = f"{loc['name']}, {loc['country']}"

        weather_url = (
            f"https://api.open-meteo.com/v1/forecast?"
            f"latitude={lat}&longitude={lon}&current_weather=true"
            f"&hourly=relativehumidity_2m&timezone=auto"
        )
        with st.spinner(f"{display_name} ë‚ ì”¨ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            w_res = requests.get(weather_url)
        if w_res.status_code != 200:
            st.error("ë‚ ì”¨ API ì˜¤ë¥˜")
            return

        js   = w_res.json()
        cw   = js.get("current_weather", {})
        temp, wind_spd, wind_dir, code = (
            cw.get("temperature"),
            cw.get("windspeed"),
            cw.get("winddirection"),
            cw.get("weathercode"),
        )
        wc_map = {
            0:"ë§‘ìŒ",1:"ì£¼ë¡œ ë§‘ìŒ",2:"ë¶€ë¶„ì  êµ¬ë¦„",3:"êµ¬ë¦„ ë§ìŒ",
            45:"ì•ˆê°œ",48:"ì•ˆê°œ(ì…ìƒ)",
            51:"ì´ìŠ¬ë¹„ ì•½í•¨",53:"ì´ìŠ¬ë¹„ ë³´í†µ",55:"ì´ìŠ¬ë¹„ ê°•í•¨",
            61:"ë¹—ë°©ìš¸ ì•½í•¨",63:"ë¹—ë°©ìš¸ ë³´í†µ",65:"ë¹—ë°©ìš¸ ê°•í•¨",
            80:"ì†Œë‚˜ê¸° ì•½í•¨",81:"ì†Œë‚˜ê¸° ë³´í†µ",82:"ì†Œë‚˜ê¸° ê°•í•¨",
            95:"ë‡Œìš°",96:"ì•½í•œ ë‡Œìš°",99:"ê°•í•œ ë‡Œìš°"
        }
        desc      = wc_map.get(code, "ì•Œ ìˆ˜ ì—†ìŒ")
        times     = js["hourly"]["time"]
        hums      = js["hourly"]["relativehumidity_2m"]
        now       = datetime.now().strftime("%Y-%m-%dT%H:00")
        humidity  = hums[times.index(now)] if now in times else None

        st.markdown(f"### {display_name} í˜„ì¬ ë‚ ì”¨")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ ê¸°ì˜¨(â„ƒ)", temp)
        c2.metric("ğŸ’¨ í’ì†(m/s)", wind_spd)
        c3.metric("ğŸŒ«ï¸ í’í–¥(Â°)", wind_dir)
        c4.metric("ğŸ’§ ìŠµë„(%)", humidity or "â€“")
        st.markdown(f"**ë‚ ì”¨ ìƒíƒœ:** {desc}")


# â”€â”€â”€ 4) Chatbot (gpt-4o) & ìš”ì•½ ê¸°ëŠ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
enc = tiktoken.encoding_for_model("gpt-4o")
MAX_TOKENS        = 262_144        # gpt-4o í—ˆìš©ì¹˜
SUMMARY_THRESHOLD = 40             # ìš”ì•½ íŠ¸ë¦¬ê±° í„´ ìˆ˜
KEEP_RECENT       = 10             # ìš”ì•½ í›„ ë‚¨ê²¨ë‘˜ ìµœì‹  ë©”ì‹œì§€ ìˆ˜

def num_tokens(messages: list) -> int:
    total = 0
    for m in messages:
        c = m["content"]
        if isinstance(c, list):
            for blk in c:
                total += len(enc.encode(
                    blk["text"] if blk["type"] == "text" else blk["image_url"]["url"]
                ))
        else:
            total += len(enc.encode(c))
    return total

@backoff.on_exception(backoff.expo, openai.RateLimitError, max_time=60, jitter=None)
def safe_chat_completion(messages, model="gpt-4o"):
    tk_in = num_tokens(messages)
    if tk_in > MAX_TOKENS:
        raise ValueError(f"ì…ë ¥ í† í° {tk_in}ê°œ â†’ ìµœëŒ€ í—ˆìš©ì¹˜({MAX_TOKENS}) ì´ˆê³¼ì…ë‹ˆë‹¤.")
    return openai.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=300,
        stream=True
    )

def compress_image(file, max_px=768, quality=85):
    img = Image.open(file)
    if max(img.size) > max_px:
        r = max_px / max(img.size)
        img = img.resize((int(img.width*r), int(img.height*r)), Image.LANCZOS)
    buf = BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=quality)
    return buf.getvalue()

def summarize_history(history: list) -> str:
    system_prompt = [{"role":"system","content":"ì•„ë˜ ëŒ€í™”ë¥¼ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."}]
    prompt = system_prompt + history + \
        [{"role":"user","content":"ì, ì´ ëŒ€í™” ë‚´ìš©ì„ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì¤˜."}]
    res = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=prompt,
        max_tokens=200
    )
    return res.choices[0].message.content.strip()

def chatgpt_clone_section():
    st.subheader("ğŸ’¬ Chatbot (gpt-4o)")

    # â”€â”€ ìƒíƒœ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.session_state.setdefault("chat_history",  [])  # UI í‘œì‹œìš©(ëª¨ë‘ ì €ì¥)
    st.session_state.setdefault("model_history", [])  # ëª¨ë¸ í˜¸ì¶œìš©(ìš”ì•½ ê°€ëŠ¥)

    img_file = st.file_uploader("ğŸ–¼ï¸ ì´ë¯¸ì§€ (ì„ íƒ)", type=["png", "jpg", "jpeg"])
    prompt   = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    # â”€â”€ 1) í•„ìš” ì‹œ model_history ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if len(st.session_state.model_history) > SUMMARY_THRESHOLD:
        try:
            summary_txt = summarize_history(st.session_state.model_history)
            recent      = st.session_state.model_history[-KEEP_RECENT:]
            st.session_state.model_history = \
                [{"role":"assistant","content":summary_txt}] + recent
        except Exception as e:
            st.error(f"ëŒ€í™” ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # â”€â”€ 2) ì´ì „ ëŒ€í™” í™”ë©´ í‘œì‹œ(chat_history ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for msg in st.session_state.chat_history:
        role, content = msg["role"], msg["content"]
        with st.chat_message("user" if role=="user" else "assistant"):
            if isinstance(content, list):               # ë©€í‹°ë¸”ë¡(user)
                for blk in content:
                    if blk["type"] == "text":
                        st.write(blk["text"])
                    else:
                        st.image(blk["image_url"]["url"],
                                 caption="ì—…ë¡œë“œ ì´ë¯¸ì§€")
            else:                                       # ë‹¨ì¼ í…ìŠ¤íŠ¸
                st.write(content)

    # â”€â”€ 3) ì…ë ¥ ì—†ìœ¼ë©´ ì¢…ë£Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if img_file is None and not prompt:
        return

    # â”€â”€ 4) ì‚¬ìš©ì ì…ë ¥ ë¸”ë¡ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    user_blocks = []
    if prompt:
        user_blocks.append({"type":"text","text":prompt})
    if img_file:
        jpg_bytes = compress_image(img_file)
        st.image(jpg_bytes,
                 caption=f"ë¯¸ë¦¬ë³´ê¸° ({len(jpg_bytes)//1024} KB)",
                 use_container_width=True)
        b64 = base64.b64encode(jpg_bytes).decode()
        user_blocks.append({
            "type":"image_url",
            "image_url":{"url":f"data:image/jpeg;base64,{b64}"}
        })

    # â”€â”€ 5) ë‘ íˆìŠ¤í† ë¦¬ì— ëª¨ë‘ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.session_state.chat_history.append({"role":"user", "content":user_blocks})
    st.session_state.model_history.append({"role":"user","content":user_blocks})

    # â”€â”€ 6) í† í° ì²´í¬ & GPT í˜¸ì¶œ(model_history ì‚¬ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if num_tokens(st.session_state.model_history) > MAX_TOKENS:
        st.error("âš ï¸ í† í° í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì˜¤ë˜ëœ ëŒ€í™”ë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ìƒˆ ì°½ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”.")
        return

    try:
        resp = safe_chat_completion(st.session_state.model_history)
        buf  = ""
        # ë¯¸ë¦¬ ë¹„ì–´ ìˆëŠ” assistant ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role":"assistant","content":""})
        st.session_state.model_history.append({"role":"assistant","content":""})

        with st.chat_message("assistant"):
            ph = st.empty()
            for chunk in resp:
                delta = chunk.choices[0].delta.content
                if delta:
                    buf += delta
                    ph.markdown(buf + "â–Œ")   # ìŠ¤íŠ¸ë¦¬ë° ì¤‘
            ph.markdown(buf)

        # ë‘ íˆìŠ¤í† ë¦¬ì— ìµœì¢… ë‹µë³€ ë°˜ì˜
        st.session_state.chat_history[-1]["content"] = buf
        st.session_state.model_history[-1]["content"] = buf

    except openai.RateLimitError:
        st.error("â³ ë ˆì´íŠ¸ ë¦¬ë°‹ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"OpenAI í˜¸ì¶œ ì˜¤ë¥˜: {e}")


# â”€â”€â”€ 5) ëŒ“ê¸€ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def comments_section():
    """
    ë¡œì»¬ CSV íŒŒì¼(comments.csv)ì„ ì‚¬ìš©í•˜ì—¬ ëŒ“ê¸€ì„ ì €ì¥í•˜ê³ , ë³´ì—¬ì£¼ëŠ” ì„¹ì…˜.
    """
    st.subheader("ğŸ—¨ï¸ ëŒ“ê¸€ ë‚¨ê¸°ê¸°")

    # 1) ëŒ“ê¸€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    comments_file = "comments.csv"

    # 2) ëŒ“ê¸€ì„ ì €ì¥í•  CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ë§Œ ìƒì„±
    if not os.path.exists(comments_file):
        df_init = pd.DataFrame(columns=["timestamp", "name", "comment"])
        df_init.to_csv(comments_file, index=False, encoding="utf-8-sig")

    # 3) ëŒ“ê¸€ì„ ì…ë ¥ë°›ì„ UI (ì´ë¦„, ëŒ“ê¸€ ë‚´ìš©, ë“±ë¡ ë²„íŠ¼)
    with st.form(key="comment_form", clear_on_submit=True):
        name = st.text_input("ì´ë¦„", max_chars=50)
        comment = st.text_area("ëŒ“ê¸€ ë‚´ìš©", height=100, max_chars=500)
        submitted = st.form_submit_button("ë“±ë¡")

    # 4) ì‚¬ìš©ìê°€ ì œì¶œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ CSVì— ì €ì¥
    if submitted:
        if not name.strip():
            st.warning("ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif not comment.strip():
            st.warning("ëŒ“ê¸€ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            # ìƒˆë¡œìš´ ëŒ“ê¸€ DataFrame
            new_row = pd.DataFrame([{
                "timestamp": ts,
                "name": name.strip(),
                "comment": comment.strip()
            }])
            # CSVì— ì´ì–´ë¶™ì´ê¸°
            new_row.to_csv(comments_file, mode="a", header=False, index=False, encoding="utf-8-sig")
            st.success("ëŒ“ê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # 5) ì €ì¥ëœ ëª¨ë“  ëŒ“ê¸€ì„ ì½ì–´ì„œ í™”ë©´ì— í‘œì‹œ
    try:
        all_comments = pd.read_csv(comments_file, encoding="utf-8-sig")
        # ìµœì‹ ìˆœìœ¼ë¡œ í‘œì‹œí•˜ë ¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì •ë ¬
        all_comments = all_comments.sort_values(by="timestamp", ascending=False)
        st.markdown("#### ì „ì²´ ëŒ“ê¸€")
        for _, row in all_comments.iterrows():
            st.markdown(f"- **[{row['timestamp']}] {row['name']}**: {row['comment']}")
    except Exception as e:
        st.error(f"ëŒ“ê¸€ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

#----6) ESG í™œë™ ì°¸ì—¬ ê¸°ë¡ 

def participation_section():
    st.subheader("ğŸ–Šï¸ ESG í™œë™ ì°¸ì—¬")

    # â”€â”€ 1) í•­ëª© ëª©ë¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    BASE_ACTIVITIES = [
        "ê°œì¸ í…€ë¸”ëŸ¬Â·ë¨¸ê·¸ì” ì‚¬ìš©",
        "ì¢…ì´ ëŒ€ì‹  ë””ì§€í„¸ ë¬¸ì„œ í™œìš©",
        "í‡´ê·¼ ì „ ë©€í‹°íƒ­ â€˜OFFâ€™",
        "ìƒí™œ ì† ì´ë©´ì§€ ì‚¬ìš©",
        "ë¶„ë¦¬ë°°ì¶œ ìƒí™œí™” ì¸ì¦",
        "ì¹œí™˜ê²½ ì¸ì¦ ì œí’ˆÂ·ì›ë‘ ì„ íƒ",
        "ì ì‹¬ì‹œê°„ â€˜ì”ë°˜ ì œë¡œâ€™ ìº í˜ì¸",
        "íƒ„ì†Œë°°ì¶œ í‘œì‹œÂ·ì¹œí™˜ê²½ ë°°ì†¡ ì„œë¹„ìŠ¤ ì´ìš©",
        "ì‚¬ë‚´ ì¼íšŒìš©í’ˆ ì‚¬ìš© ì¤„ì´ê¸°",
    ]

    
    img_dir, csv_file = "participation_images", "participation.csv"
    os.makedirs(img_dir, exist_ok=True)

    # â”€â”€ 2) CSV í—¤ë” ìˆœì„œ êµì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    expected_cols = ["timestamp","department","name","activity","image_filename"]
    if os.path.exists(csv_file):
        df0 = pd.read_csv(csv_file, nrows=0, encoding="utf-8-sig")
        if list(df0.columns) != expected_cols and set(df0.columns) == set(expected_cols):
            df_bad = pd.read_csv(csv_file, encoding="utf-8-sig")
            df_bad = df_bad[expected_cols]
            df_bad.to_csv(csv_file, index=False, encoding="utf-8-sig")
    else:
        pd.DataFrame(columns=expected_cols).to_csv(csv_file, index=False, encoding="utf-8-sig")

    # â”€â”€ 3) í™œë™ ì…ë ¥ ë°©ì‹ (í¼ ë°–) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mode = st.radio(
        "í™œë™ ì…ë ¥ ë°©ì‹",
        ["ëª©ë¡ì—ì„œ ì„ íƒ", "ì§ì ‘ ì…ë ¥"],
        horizontal=True,
        key="reg_mode"
    )
    if mode == "ëª©ë¡ì—ì„œ ì„ íƒ":
        activity = st.selectbox("ê¸°ë³¸ í™œë™ í•­ëª© ì¤‘ ì„ íƒ", BASE_ACTIVITIES, key="reg_select")
    else:
        activity = st.text_input("ì§ì ‘ ì…ë ¥: í™œë™ ë‚´ìš©", placeholder="ì˜ˆ) ì‚¬ë¬´ì‹¤ LED ì¡°ëª… êµì²´", key="reg_text")

    st.markdown("---")

    # â”€â”€ 4) ì‹ ê·œ ë“±ë¡ í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.form(key="participation_form", clear_on_submit=True):
        dept      = st.text_input("ì°¸ì—¬ ë¶€ì„œ", max_chars=50)
        person    = st.text_input("ì„±ëª…", max_chars=30)
        up_img    = st.file_uploader("ì¦ëª…ìë£Œ(ì´ë¯¸ì§€)", type=["png","jpg","jpeg"])
        submitted = st.form_submit_button("ì œì¶œ")

    if submitted:
        if not dept.strip():
            st.warning("ì°¸ì—¬ ë¶€ì„œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif not person.strip():
            st.warning("ì„±ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif not activity.strip():
            st.warning("í™œë™ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif up_img is None:
            st.warning("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        else:
            ts        = datetime.now().strftime("%Y%m%d_%H%M%S")
            ext       = os.path.splitext(up_img.name)[1].lower()
            safe_name = "".join(person.split())
            img_fname = f"{ts}_{safe_name}{ext}"
            # ì´ë¯¸ì§€ ì €ì¥
            with open(os.path.join(img_dir, img_fname), "wb") as f:
                f.write(up_img.getbuffer())

            # CSVì— ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ê¸°ë¡
            pd.DataFrame([{
                "timestamp":     datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "department":    dept.strip(),
                "name":          person.strip(),
                "activity":      activity.strip(),
                "image_filename": img_fname
            }]).to_csv(csv_file, mode="a", header=False, index=False,
                       encoding="utf-8-sig")

            st.success("âœ… ì°¸ì—¬ ì •ë³´ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")


    # â”€â”€ 5) ì €ì¥ëœ ë°ì´í„° ë¡œë“œ ë° í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        all_data = pd.read_csv(csv_file, encoding="utf-8-sig")
        all_data = all_data.loc[:, expected_cols]  # ìˆœì„œ ë³´ì¥
        all_data = all_data.sort_values(by="timestamp", ascending=False).reset_index(drop=True)

        # ì´ë²ˆì£¼ì˜ ìš°ìˆ˜ ESG ì‚¬ì› (ê°€ì¥ ë§ì´ ë“±ë¡í•œ ì´ë¦„)
        if not all_data.empty:
            top_name = all_data["name"].value_counts().idxmax()
            st.markdown(f"### ğŸ† ì´ë²ˆì£¼ì˜ ìš°ìˆ˜ ESG ì‚¬ì›: **{top_name}**")

        # ë‹¤ìš´ë¡œë“œ ë§í¬
        b64 = base64.b64encode(
            all_data.to_csv(index=False, encoding="utf-8-sig").encode()
        ).decode()
        st.markdown(
            f'<a href="data:file/csv;base64,{b64}" download="participation.csv">ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ</a>',
            unsafe_allow_html=True
        )

        st.dataframe(all_data, use_container_width=True)
        ...

        # â”€â”€ 6) ë°ì´í„° ìˆ˜ì •(expander) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with st.expander("âœï¸ ë°ì´í„° ìˆ˜ì •", expanded=False):
            if all_data.empty:
                st.info("ìˆ˜ì •í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                idx = st.selectbox(
                    "ìˆ˜ì •í•  í•­ëª© ì„ íƒ",
                    all_data.index,
                    format_func=lambda i: f"{all_data.loc[i,'timestamp']} / {all_data.loc[i,'name']}"
                )
                if idx is not None:
                    cur = all_data.loc[idx]
                    # ìˆ˜ì •ìš© í™œë™ ì…ë ¥ ë°©ì‹
                    edit_mode = st.radio(
                        "í™œë™ ì…ë ¥ ë°©ì‹",
                        ["ëª©ë¡ì—ì„œ ì„ íƒ", "ì§ì ‘ ì…ë ¥"],
                        horizontal=True,
                        key=f"edit_mode_{idx}"
                    )
                    if edit_mode == "ëª©ë¡ì—ì„œ ì„ íƒ":
                        new_act = st.selectbox(
                            "í™œë™ í•­ëª©",
                            BASE_ACTIVITIES,
                            index=BASE_ACTIVITIES.index(cur["activity"])
                                     if cur["activity"] in BASE_ACTIVITIES else 0,
                            key=f"edit_sel_{idx}"
                        )
                    else:
                        new_act = st.text_input(
                            "ì§ì ‘ ì…ë ¥: í™œë™ ë‚´ìš©",
                            value=cur["activity"],
                            key=f"edit_text_{idx}"
                        )

                    new_dept = st.text_input("ë¶€ì„œ", value=cur["department"], key=f"edit_dept_{idx}")
                    new_name = st.text_input("ì„±ëª…", value=cur["name"], key=f"edit_name_{idx}")
                    new_img  = st.file_uploader("ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ(ì„ íƒ)", type=["png","jpg","jpeg"], key=f"edit_img_{idx}")

                    if st.button("ì €ì¥", key=f"save_edit_{idx}"):
                        if not new_act.strip():
                            st.warning("í™œë™ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                        else:
                            img_fname = cur["image_filename"]
                            if new_img is not None:
                                # êµ¬ ì´ë¯¸ì§€ ì‚­ì œ
                                old_p = os.path.join(img_dir, img_fname)
                                if os.path.exists(old_p):
                                    os.remove(old_p)
                                ext       = os.path.splitext(new_img.name)[1].lower()
                                img_fname = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{''.join(new_name.split())}{ext}"
                                with open(os.path.join(img_dir, img_fname), "wb") as f:
                                    f.write(new_img.getbuffer())

                            # ìˆ˜ì •ëœ ë‚´ìš© ë®ì–´ì“°ê¸° (activity ì»¬ëŸ¼ë„ ì œëŒ€ë¡œ ë³€ê²½)
                            all_data.loc[idx, ["department","name","activity","image_filename"]] = [
                                new_dept.strip(), new_name.strip(), new_act.strip(), img_fname
                            ]
                            all_data.to_csv(csv_file, index=False, encoding="utf-8-sig")
                            st.success("âœ… ìˆ˜ì • ì™„ë£Œ")
                            st.experimental_rerun()

        # â”€â”€ 7) ë°ì´í„° ì‚­ì œ(expander) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ", expanded=False):
            if all_data.empty:
                st.info("ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                del_idxs = st.multiselect(
                    "ì‚­ì œí•  í•­ëª© ì„ íƒ",
                    all_data.index,
                    format_func=lambda i: f"{all_data.loc[i,'timestamp']} / {all_data.loc[i,'name']}"
                )
                if st.button("ì‚­ì œ", key="delete_rows"):
                    for i in del_idxs:
                        p = os.path.join(img_dir, all_data.loc[i,"image_filename"])
                        if os.path.exists(p):
                            os.remove(p)
                    all_data = all_data.drop(del_idxs).reset_index(drop=True)
                    all_data.to_csv(csv_file, index=False, encoding="utf-8-sig")
                    st.success("ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ")
                    st.experimental_rerun()

        # â”€â”€ 8) ì¸ë„¤ì¼ + ì •ë³´ í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for _, row in all_data.iterrows():
            c1, c2 = st.columns([1, 4])
            with c1:
                img_path = os.path.join(img_dir, row["image_filename"])
                st.image(img_path if os.path.exists(img_path) else None,
                         width=80, caption=row["name"])
            with c2:
                st.write(
                    f"- **[{row['timestamp']}]** {row['department']} / {row['name']}  \n"
                    f"  ğŸš© _{row['activity']}_"
                )

    except Exception as e:
        st.error(f"ì°¸ì—¬ í˜„í™© ì˜¤ë¥˜: {e}")




# â”€â”€â”€ 7) ì˜ìƒ ëª¨ìŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def video_collection_section():
    st.subheader("ğŸ“º ESG ì˜ìƒ ëª¨ìŒ")
    # 1. ì‚¬ë¬´ì‹¤ì—ì„œ ì´ë©´ì§€ í™œìš©í•˜ê¸°!
    st.markdown("#### ì‚¬ë¬´ì‹¤ì—ì„œ ì´ë©´ì§€ í™œìš©í•˜ê¸°!")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%82%AC%EB%AC%B4%EC%8B%A4%EC%97%90%EC%84%9C%20%EC%9D%B4%EB%A9%B4%EC%A7%80%20%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0.mp4")
    st.write("")  # ì¤„ ê°„ê²©

    # 2. ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 1íƒ„
    st.markdown("#### ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 1íƒ„")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%B9%B4%ED%8E%98%EC%97%90%EC%84%9C%20%ED%85%80%EB%B8%94%EB%9F%AC%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0.mp4")
    st.write("")

    # 3. ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 2íƒ„
    st.markdown("#### ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 2íƒ„")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%B9%B4%ED%8E%98%EC%97%90%EC%84%9C%20%ED%9C%B4%EC%A7%80%20%EC%A0%81%EA%B2%8C%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0.mp4")

    # 4. íšŒì˜ì‹¤ì—ì„œ ë¶ˆ ë„ê¸° 
    st.markdown("#### íšŒì˜ì‹¤ì—ì„œ ë¶ˆ ë„ê¸°")
    st.video("https://storage.googleapis.com/videoupload_icpa/%ED%9A%8C%EC%9D%98%EC%8B%A4%EC%97%90%EC%84%9C%20%EB%B6%88%EB%81%84%EA%B8%B0.mp4")

    # 5.ì¼íšŒìš©í’ˆ ì‚¬ìš© ì¤„ì´ê¸°
    st.markdown("#### ì¼íšŒìš©í’ˆ ì‚¬ìš© ì¤„ì´ê¸°")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%9D%BC%ED%9A%8C%EC%9A%A9%ED%92%88%20%EC%82%AC%EC%9A%A9%20%EC%A4%84%EC%9D%B4%EA%B8%B0.mp4")
    
    # 5.ë¶„ë¦¬ìˆ˜ê±°ì¥ì—ì„œ ESG ì‹¤ì²œí•˜ê¸°
    st.markdown("#### ë¶„ë¦¬ìˆ˜ê±°ì¥ì—ì„œ ESG ì‹¤ì²œí•˜ê¸°")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EB%B6%84%EB%A6%AC%EC%88%98%EA%B1%B0%EC%9E%A5%EC%97%90%EC%84%9C%20%EC%8B%A4%EC%B2%9C%ED%95%98%EB%8A%94%20ESG%20.mp4")

    
# 1) í”„ë¡œì íŠ¸ íŒ€ ì†Œê°œ ì„¹ì…˜ í•¨ìˆ˜ ì¶”ê°€
def project_team_intro_section():
    st.subheader("í”„ë¡œì íŠ¸ íŒ€ ì†Œê°œ")
    st.markdown("""
ì•ˆë…•í•˜ì„¸ìš”. í•­ë§Œê³µì‚¬ ì¼ê²½í—˜ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ESGë¥¼ ì£¼ì œë¡œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ëŠ” íŒ€ INUSì…ë‹ˆë‹¤.

ì €í¬ íŒ€ì€ "ESG" ìº í˜ì¸ì„ ì£¼ì œë¡œ ì§„í–‰í•˜ê³ ì í•˜ë˜ ì¤‘, ì–´ë–»ê²Œ í•˜ë©´ ì‚¬ë‚´ êµ¬ì„±ì›ë“¤ì˜ ì°¸ì—¬ë¥¼ ìœ ë„í•  ìˆ˜ ìˆì„ê¹Œ ê³ ë¯¼í•˜ë˜ ì¤‘ì—, í™ˆí˜ì´ì§€ë¥¼ ê°„ë‹¨í•˜ê²Œ ì œì‘í•˜ì—¬ ìº í˜ì¸ì„ ì§„í–‰í•˜ê³ ì í•˜ì˜€ìŠµë‹ˆë‹¤.

1ì£¼ì¼ê°„ì˜ ì§§ì€ ê¸°ê°„ë™ì•ˆ ìº í˜ì¸ì„ ì§„í–‰í•˜ê²Œ ë˜ì—ˆì§€ë§Œ, ì €í¬ íŒ€ì˜ ë©˜í† ë¥¼ ë‹´ë‹¹í•´ì£¼ì‹œëŠ” ì„ì§€ì˜ ëŒ€ë¦¬ë‹˜ê»˜ì„œ ë„ì™€ì£¼ì‹  ë•ë¶„ì— ì €í¬ì˜ ë…¸ë ¥ì´ ë¹›ì„ ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¸ì²œ í•­ë§Œê³µì‚¬ êµ¬ì„±ì› ë¶„ë“¤ì˜ ë§ì€ ì°¸ì—¬ì™€, í•´ë‹¹ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•¨ì— ìˆì–´ì„œ ë„ì™€ì£¼ì‹  ë¶„ë“¤ê»˜ ê³ ë§ˆì›€ì„ í‘œí•˜ê³ ì í•©ë‹ˆë‹¤.

ì €í¬ íŒ€ì´ ì œì‘í•œ ì‚¬ì´íŠ¸ì— ëŒ€í•´ì„œ ê°œëµì ìœ¼ë¡œ ì„¤ëª… ë“œë¦¬ìë©´, ESG ìº í˜ì¸ í™œë™ì„ ê¸°ë¡í•  ìˆ˜ ìˆëŠ” tab, ì €í¬ íŒ€ì—ì„œ ì œì‘í•œ ì˜ìƒ ì»¨í…ì¸ ë¥¼ ê°ìƒí•  ìˆ˜ ìˆëŠ” tab, êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ë§í¬ë¥¼ ë³µì‚¬í•  ìˆ˜ ìˆëŠ” tab, ì„ ë°•ê´€ì œì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” tab, chat GPTë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì±—ë´‡ tab, ì—¬ëŸ¬ ì˜ê²¬ì„ ë‚¨ê¸¸ ìˆ˜ ìˆëŠ” ëŒ“ê¸€ tab, ì˜¤ëŠ˜ì˜ ë‚ ì”¨ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” tabìœ¼ë¡œ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

íŒ€ êµ¬ì„±
- ë©˜í†  : ì„ì§€ì˜ ëŒ€ë¦¬ [ì¸ì²œí•­ë§Œê³µì‚¬]
- íŒ€ì¥ : ë°•ì„í›ˆ [ì¸ì²œëŒ€í•™êµ ë™ë¶ì•„ ë¬¼ë¥˜ëŒ€í•™ì› ìœµí•©ë¬¼ë¥˜ì‹œìŠ¤í…œ ì „ê³µ]
- íŒ€ì› : ì´ë™ë¯¼ [ì¸ì²œëŒ€í•™êµ ë™ë¶ì•„ êµ­ì œí†µìƒë¬¼ë¥˜í•™ë¶€ ì „ê³µ]
- íŒ€ì› : ê¹€ë„í˜„ [ì¸ì²œëŒ€í•™êµ ë™ë¶ì•„ êµ­ì œí†µìƒë¬¼ë¥˜í•™ë¶€ ì „ê³µ]
- íŒ€ì› : ê¹€ë„ìœ¤ [ì¸ì²œëŒ€í•™êµ ê²½ì œí•™ë¶€ ì „ê³µ]
""")




# â”€â”€â”€ 8) ì•± ë ˆì´ì•„ì›ƒ (íƒ­ êµ¬ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ì¸ì²œí•­ë§Œê³µì‚¬ ESG í†µí•© í¬í„¸", layout="centered")
st.title("ğŸ“ˆ ì¸ì²œí•­ë§Œê³µì‚¬ ESG í†µí•© í¬í„¸")

tabs = st.tabs([
    "ESG í™œë™ ì°¸ì—¬", "ESG ì˜ìƒ ëª¨ìŒ","êµ¬ê¸€ ë‰´ìŠ¤", "ì„ ë°• ê´€ì œì •ë³´","ì±—ë´‡[GPT-4o]", "ëŒ“ê¸€","ì˜¤ëŠ˜ì˜ ë‚ ì”¨", "í”„ë¡œì íŠ¸ íŒ€ ì†Œê°œ"
])

with tabs[0]:
    participation_section()

with tabs[1]:
    video_collection_section()

with tabs[2]:
    google_news_section()

with tabs[3]:
    vessel_monitoring_section()

with tabs[4]:
    chatgpt_clone_section()

with tabs[5]:
    comments_section()

with tabs[6]:
    today_weather_section()

with tabs[7]:
    project_team_intro_section()














