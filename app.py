# app.py  |  Streamlit í†µí•© ë°ëª¨
import os
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import feedparser
import requests
from datetime import datetime, date
from urllib.parse import urlencode, quote_plus

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•˜ë“œì½”ë”©ëœ API í‚¤ ë° í™˜ê²½ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("ODCLOUD_API_KEY", "YOUR_DEFAULT_API_KEY")
OLLAMA_ENDPOINT = os.getenv("OLLAMA_ENDPOINT", "https://api.ollama.cloud/v1/completions")
OLLAMA_API_KEY  = os.getenv("OLLAMA_API_KEY", "")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ (Google News RSS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=300)
def fetch_google_news(keyword: str, max_items: int = 10):
    clean_kw = " ".join(keyword.strip().split())
    params = {"q": clean_kw, "hl": "ko", "gl": "KR", "ceid": "KR:ko"}
    rss_url = "https://news.google.com/rss/search?" + urlencode(params, doseq=True)
    feed = feedparser.parse(rss_url)

    items = []
    for entry in feed.entries[:max_items]:
        pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        source   = entry.get("source", {}).get("title", "")
        items.append({
            "title":  entry.title,
            "link":   entry.link,
            "source": source,
            "date":   pub_date,
        })
    return items

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CSV íˆìŠ¤í† ê·¸ë¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sample_data_section():
    st.subheader("ğŸ“Š ìƒ˜í”Œ ë°ì´í„° íˆìŠ¤í† ê·¸ë¨")
    uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ (optional)", type=["csv"])
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df)
        nums = df.select_dtypes(include="number").columns.tolist()
        if nums:
            col = st.selectbox("Numeric ì»¬ëŸ¼ ì„ íƒ", nums)
            fig, ax = plt.subplots()
            ax.hist(df[col], bins=10)
            ax.set_xlabel(col)
            ax.set_ylabel("Frequency")
            st.pyplot(fig)
    else:
        st.info("CSV íŒŒì¼ì„ ì˜¬ë¦¬ë©´ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°ì™€ íˆìŠ¤í† ê·¸ë¨ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ë™ì˜ìƒ ì—…ë¡œë“œÂ·ì¬ìƒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def video_upload_section():
    st.subheader("ğŸ“¹ ë™ì˜ìƒ ì—…ë¡œë“œ & ì¬ìƒ")
    video_file = st.file_uploader("ë™ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ (MP4 / MOV / AVI)", type=["mp4","mov","avi"])
    if video_file:
        st.video(video_file)
    else:
        st.info("ìœ„ ë²„íŠ¼ìœ¼ë¡œ ë™ì˜ìƒ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vessel_monitoring_section():
    st.subheader("ğŸš¢ í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ")
    date_from = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", date.today())
    date_to   = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", date.today())
    page      = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", 1, 1000, 1)
    per_page  = st.slider("í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê±´ìˆ˜", 1, 1000, 100)
    if st.button("ğŸ” ì¡°íšŒ", key="vessel_btn"):
        params = {
            "serviceKey": API_KEY,
            "page":       page,
            "perPage":    per_page,
            "fromDate":   date_from.strftime("%Y-%m-%d"),
            "toDate":     date_to.strftime("%Y-%m-%d"),
        }
        with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            try:
                res = requests.get("https://api.odcloud.kr/api/15128156/v1/uddi:fdcdb0d1-0296-4c3b-8087-8ab4bd4d5123", params=params)
                res.raise_for_status()
                data = res.json()
            except requests.HTTPError as e:
                st.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
                st.text(res.text)
                return
        if data.get("data"):
            df = pd.DataFrame(data["data"])
            st.success(f"ì´ {data.get('totalCount', len(df))} ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì„¹ì…˜ (ë™ì  ë„ì‹œ ê²€ìƒ‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def today_weather_section():
    st.subheader("â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì¡°íšŒ")
    city = st.text_input("ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: Seoul, ì„œìš¸)", value="Seoul")
    if st.button("ğŸ” ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°", key="weather_btn"):
        # ì§€ì˜¤ì½”ë”©
        geo_url = f"https://geocoding-api.open-meteo.com/v1/search?name={quote_plus(city)}&count=1&language=ko&format=json"
        geo_res = requests.get(geo_url)
        if geo_res.status_code != 200:
            st.error(f"ì§€ì˜¤ì½”ë”© ì˜¤ë¥˜({geo_res.status_code}): {geo_res.text}")
            return
        results = geo_res.json().get("results")
        if not results:
            st.error("ë„ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        lat, lon = results[0]["latitude"], results[0]["longitude"]
        name = results[0].get("name_local", results[0]["name"])
        # ë‚ ì”¨
        weather_url = (
            f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
            f"&current_weather=true&hourly=relativehumidity_2m&timezone=Asia/Seoul"
        )
        w_res = requests.get(weather_url)
        if w_res.status_code != 200:
            st.error(f"ë‚ ì”¨ ì¡°íšŒ ì˜¤ë¥˜({w_res.status_code}): {w_res.text}")
            return
        w_js = w_res.json()
        cw = w_js.get("current_weather", {})
        temp, wind_spd, wind_dir, code = cw.get("temperature"), cw.get("windspeed"), cw.get("winddirection"), cw.get("weathercode")
        wc_map = {0:"ë§‘ìŒ",1:"ì£¼ë¡œ ë§‘ìŒ",2:"ë¶€ë¶„ì  êµ¬ë¦„",3:"êµ¬ë¦„ ë§ìŒ",45:"ì•ˆê°œ",48:"ì•ˆê°œ(ì…ìƒ)",
                  51:"ì´ìŠ¬ë¹„ ì•½í•¨",53:"ì´ìŠ¬ë¹„ ë³´í†µ",55:"ì´ìŠ¬ë¹„ ê°•í•¨",61:"ë¹—ë°©ìš¸ ì•½í•¨",63:"ë¹—ë°©ìš¸ ë³´í†µ",65:"ë¹—ë°©ìš¸ ê°•í•¨",
                  80:"ì†Œë‚˜ê¸° ì•½í•¨",81:"ì†Œë‚˜ê¸° ë³´í†µ",82:"ì†Œë‚˜ê¸° ê°•í•¨",95:"ë‡Œìš°",96:"ì•½í•œ ë‡Œìš°",99:"ê°•í•œ ë‡Œìš°"}
        desc = wc_map.get(code,"ì•Œ ìˆ˜ ì—†ìŒ")
        times, hums = w_js["hourly"]["time"], w_js["hourly"]["relativehumidity_2m"]
        now = datetime.now().strftime("%Y-%m-%dT%H:00")
        humidity = hums[times.index(now)] if now in times else None
        st.markdown(f"### {name} í˜„ì¬ ë‚ ì”¨")
        c1,c2,c3,c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ ê¸°ì˜¨(â„ƒ)", temp)
        c2.metric("ğŸ’¨ í’ì†(m/s)", wind_spd)
        c3.metric("ğŸŒ«ï¸ í’í–¥(Â°)", wind_dir)
        c4.metric("ğŸ’§ ìŠµë„(%)", humidity if humidity is not None else "â€“")
        st.markdown(f"**ë‚ ì”¨ ìƒíƒœ:** {desc}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6) LLM í…ŒìŠ¤íŠ¸ (Ollama Cloud) ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_with_ollama(prompt: str) -> str:
    headers = {"Authorization": f"Bearer {OLLAMA_API_KEY}", "Content-Type": "application/json"}
    payload = {"model": "seokhoon/IPA", "prompt": prompt, "temperature":0.7, "max_tokens":256}
    r = requests.post(OLLAMA_ENDPOINT, json=payload, headers=headers)
    try:
        r.raise_for_status()
    except requests.HTTPError:
        return f"Error {r.status_code}: {r.text}"
    return r.json().get("choices", [{}])[0].get("text", "")

def llm_section():
    st.subheader("ğŸ¤– LLM í…ŒìŠ¤íŠ¸ (Ollama Cloud)")
    prompt = st.text_area("í”„ë¡¬í”„íŠ¸ ì…ë ¥", height=150)
    if st.button("ìƒì„±", key="llm_btn"):
        with st.spinner("LLM í˜¸ì¶œ ì¤‘â€¦"):
            out = generate_with_ollama(prompt)
        st.markdown("### ì‘ë‹µ")
        st.write(out)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7) ì•± ë ˆì´ì•„ì›ƒ (íƒ­ êµ¬ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="í†µí•© ë°ëª¨", layout="centered")
st.title("ğŸ“ˆ í†µí•© ë°ëª¨: ë‰´ìŠ¤Â·ë°ì´í„°Â·ë™ì˜ìƒÂ·ì„ ë°•Â·ë‚ ì”¨Â·LLM")

tabs = st.tabs(["êµ¬ê¸€ ë‰´ìŠ¤","ë°ì´í„° íˆìŠ¤í† ê·¸ë¨","ë™ì˜ìƒ ì¬ìƒ","ì„ ë°• ê´€ì œì •ë³´","ì˜¤ëŠ˜ì˜ ë‚ ì”¨","LLM í…ŒìŠ¤íŠ¸"])
with tabs[0]:
    st.subheader("â–¶ êµ¬ê¸€ ë‰´ìŠ¤ í¬ë¡¤ë§ (RSS)")
    kw = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", "ESG", key="kw_input")
    num = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ê°œìˆ˜", 5, 20, 10, key="num_slider")
    if st.button("ë³´ê¸°", key="news_btn"):
        with st.spinner(f"â€˜{kw}â€™ ë‰´ìŠ¤ ë¡œë”©â€¦"):
            for it in fetch_google_news(kw, num): st.markdown(f"- **[{it['source']} Â· {it['date']}]** [{it['title']}]({it['link']})")
with tabs[1]: sample_data_section()
with tabs[2]: video_upload_section()
with tabs[3]: vessel_monitoring_section()
with tabs[4]: today_weather_section()
with tabs[5]: llm_section()
with tabs[5]:
    llm_section()

