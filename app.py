# app.py  |  Streamlit í†µí•© ë°ëª¨
import os
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import feedparser
import requests
from datetime import datetime, date
from urllib.parse import urlencode, quote_plus

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ë³€ìˆ˜ ë° í•˜ë“œì½”ë”©ëœ API í‚¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.getenv("ODCLOUD_API_KEY", "GprdI3W07y8Ul7R0KwyRE0Beb1Y2wqtlBuvzWRqLqIZzEkR7xrPePc6CMQeD9FQAsTyQHh1V8NDK1md4ou4WGw==")
OLLAMA_ENDPOINT = os.getenv("OLLAMA_ENDPOINT", "https://api.ollama.cloud/v1/completions")
OLLAMA_API_KEY  = os.getenv("OLLAMA_API_KEY", "sk-XXXXXXXXXXXXXXXXXXXXXXXX")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ (Google News RSS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=300)
def fetch_google_news(keyword: str, max_items: int = 10):
    clean_kw = " ".join(keyword.strip().split())
    params = {"q": clean_kw, "hl": "ko", "gl": "KR", "ceid": "KR:ko"}
    rss_url = "https://news.google.com/rss/search?" + urlencode(params, doseq=True)
    feed = feedparser.parse(rss_url)
    items = []
    for entry in feed.entries[:max_items]:
        pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        source   = entry.get("source", {}).get("title", "")
        items.append({
            "title": entry.title,
            "link":  entry.link,
            "source": source,
            "date":   pub_date,
        })
    return items

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CSV íˆìŠ¤í† ê·¸ë¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sample_data_section():
    st.subheader("ğŸ“Š ìƒ˜í”Œ ë°ì´í„° íˆìŠ¤í† ê·¸ë¨")
    uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ (optional)", type=["csv"], key="hist_csv")
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df)
        nums = df.select_dtypes(include="number").columns.tolist()
        if nums:
            col = st.selectbox("Numeric ì»¬ëŸ¼ ì„ íƒ", nums, key="hist_col")
            fig, ax = plt.subplots()
            ax.hist(df[col], bins=10)
            ax.set_xlabel(col)
            ax.set_ylabel("Frequency")
            st.pyplot(fig)
    else:
        st.info("CSV íŒŒì¼ì„ ì˜¬ë¦¬ë©´ íˆìŠ¤í† ê·¸ë¨ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ë™ì˜ìƒ ì—…ë¡œë“œÂ·ì¬ìƒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def video_upload_section():
    st.subheader("ğŸ“¹ ë™ì˜ìƒ ì—…ë¡œë“œ & ì¬ìƒ")
    video_file = st.file_uploader("ë™ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ (MP4/MOV/AVI)", type=["mp4","mov","avi"], key="vid_file")
    if video_file:
        st.video(video_file)
    else:
        st.info("íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vessel_monitoring_section():
    st.subheader("ğŸš¢ í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ")
    date_from = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", date.today(), key="vessel_from")
    date_to   = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", date.today(), key="vessel_to")
    page      = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", 1, 1000, 1, key="vessel_page")
    per_page  = st.slider("í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê±´ìˆ˜", 1, 1000, 100, key="vessel_perpage")
    if st.button("ğŸ” ì¡°íšŒ", key="vessel_search"):
        params = {
            "serviceKey": API_KEY,
            "page":       page,
            "perPage":    per_page,
            "fromDate":   date_from.strftime("%Y-%m-%d"),
            "toDate":     date_to.strftime("%Y-%m-%d"),
        }
        with st.spinner("ì¡°íšŒ ì¤‘â€¦"):
            res = requests.get(
                "https://api.odcloud.kr/api/15128156/v1/uddi:fdcdb0d1-0296-4c3b-8087-8ab4bd4d5123",
                params=params
            )
            if res.status_code != 200:
                st.error(f"API ì˜¤ë¥˜ {res.status_code}")
                st.text(res.text)
                return
            data = res.json()
        if data.get("data"):
            df = pd.DataFrame(data["data"])
            st.success(f"ì´ {data.get('totalCount', len(df))} ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def today_weather_section():
    st.subheader("â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì¡°íšŒ")
    # ì„ íƒí˜• ë„ì‹œ ëª©ë¡
    city = st.selectbox(
        "ë„ì‹œ ì„ íƒ",
        ["Seoul", "Busan", "Incheon"],
        format_func=lambda x: {"Seoul":"ì„œìš¸","Busan":"ë¶€ì‚°","Incheon":"ì¸ì²œ"}[x],
        key="weather_city"
    )
    if st.button("ğŸ” ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°", key="weather_search"):
        coords = {"Seoul":(37.5665,126.9780),"Busan":(35.1796,129.0756),"Incheon":(37.4563,126.7052)}
        lat, lon = coords[city]
        url = (
            f"https://api.open-meteo.com/v1/forecast?"
            f"latitude={lat}&longitude={lon}&current_weather=true"
            f"&hourly=relativehumidity_2m&timezone=Asia/Seoul"
        )
        with st.spinner(f"{city} ë‚ ì”¨ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            w_res = requests.get(url)
            w_res.raise_for_status()
            js = w_res.json()
        cw = js.get("current_weather", {})
        temp, wind_spd, wind_dir, code = (
            cw.get("temperature"), cw.get("windspeed"),
            cw.get("winddirection"), cw.get("weathercode")
        )
        wc_map = {0:"ë§‘ìŒ",1:"ì£¼ë¡œ ë§‘ìŒ",2:"ë¶€ë¶„ì  êµ¬ë¦„",3:"êµ¬ë¦„ ë§ìŒ",
                  45:"ì•ˆê°œ",48:"ì•ˆê°œ(ì…ìƒ)",
                  51:"ì´ìŠ¬ë¹„ ì•½í•¨",53:"ì´ìŠ¬ë¹„ ë³´í†µ",55:"ì´ìŠ¬ë¹„ ê°•í•¨",
                  61:"ë¹—ë°©ìš¸ ì•½í•¨",63:"ë¹—ë°©ìš¸ ë³´í†µ",65:"ë¹—ë°©ìš¸ ê°•í•¨",
                  80:"ì†Œë‚˜ê¸° ì•½í•¨",81:"ì†Œë‚˜ê¸° ë³´í†µ",82:"ì†Œë‚˜ê¸° ê°•í•¨",
                  95:"ë‡Œìš°",96:"ì•½í•œ ë‡Œìš°",99:"ê°•í•œ ë‡Œìš°"}
        desc = wc_map.get(code, "ì•Œ ìˆ˜ ì—†ìŒ")
        times, hums = js["hourly"]["time"], js["hourly"]["relativehumidity_2m"]
        now = datetime.now().strftime("%Y-%m-%dT%H:00")
        humidity = hums[times.index(now)] if now in times else None
        st.markdown(f"### {city} í˜„ì¬ ë‚ ì”¨")
        c1,c2,c3,c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ ê¸°ì˜¨(â„ƒ)", temp)
        c2.metric("ğŸ’¨ í’ì†(m/s)", wind_spd)
        c3.metric("ğŸŒ«ï¸ í’í–¥(Â°)", wind_dir)
        c4.metric("ğŸ’§ ìŠµë„(%)", humidity if humidity is not None else "â€“")
        st.markdown(f"**ë‚ ì”¨ ìƒíƒœ:** {desc}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6) LLM í…ŒìŠ¤íŠ¸ (Ollama Cloud) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_with_ollama(prompt: str) -> str:
    headers = {"Authorization":f"Bearer {OLLAMA_API_KEY}","Content-Type":"application/json"}
    payload = {"model":"seokhoon/IPA","prompt":prompt,"temperature":0.7,"max_tokens":256}
    r = requests.post(OLLAMA_ENDPOINT,json=payload,headers=headers)
    if r.status_code != 200:
        return f"LLM ì˜¤ë¥˜ {r.status_code}: {r.text}"
    return r.json().get("choices",[{}])[0].get("text","")

def llm_section():
    st.subheader("ğŸ¤– LLM í…ŒìŠ¤íŠ¸ (Ollama Cloud)")
    prompt = st.text_area("í”„ë¡¬í”„íŠ¸ ì…ë ¥",height=150,key="llm_prompt")
    if st.button("ìƒì„±",key="llm_generate"):
        with st.spinner("LLM í˜¸ì¶œ ì¤‘â€¦"):
            out = generate_with_ollama(prompt)
        st.markdown("### ì‘ë‹µ")
        st.write(out)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7) ì•± ë ˆì´ì•„ì›ƒ (íƒ­ êµ¬ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="í†µí•© ë°ëª¨",layout="centered")
st.title("ğŸ“ˆ í†µí•© ë°ëª¨: ë‰´ìŠ¤Â·ë°ì´í„°Â·ë™ì˜ìƒÂ·ì„ ë°•Â·ë‚ ì”¨Â·LLM")

tabs = st.tabs(["êµ¬ê¸€ ë‰´ìŠ¤","ë°ì´í„° íˆìŠ¤í† ê·¸ë¨","ë™ì˜ìƒ ì¬ìƒ","ì„ ë°• ê´€ì œì •ë³´","ì˜¤ëŠ˜ì˜ ë‚ ì”¨","LLM í…ŒìŠ¤íŠ¸"])
with tabs[0]:
    st.subheader("â–¶ êµ¬ê¸€ ë‰´ìŠ¤ í¬ë¡¤ë§ (RSS)")
    kw = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ","ESG",key="news_kw")
    num = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ê°œìˆ˜",5,20,10,key="news_num")
    if st.button("ë³´ê¸°",key="news_btn"):
        with st.spinner(f"â€˜{kw}â€™ ë‰´ìŠ¤ ë¡œë”©â€¦"):
            for it in fetch_google_news(kw,num):
                st.markdown(f"- **[{it['source']} Â· {it['date']}]** [{it['title']}]({it['link']})")
with tabs[1]:
    sample_data_section()
with tabs[2]:
    video_upload_section()
with tabs[3]:
    vessel_monitoring_section()
with tabs[4]:
    today_weather_section()
with tabs[5]:
    llm_section()


