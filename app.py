# -*- coding: utf-8 -*-
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ì¸ì²œí•­ë§Œê³µì‚¬ ESG í†µí•© í¬í„¸  (ë‰´ìŠ¤ Â· ì„ ë°• Â· ë‚ ì”¨ Â· Chatbot Â· ëŒ“ê¸€ Â· í™œë™ì°¸ì—¬ Â· ì˜ìƒ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os                         # â† ì˜¤íƒ€(mport) ìˆ˜ì •
import streamlit as st
import streamlit.components.v1 as components
import openai
import base64
import backoff
import tiktoken
import time
import pandas as pd
import matplotlib.pyplot as plt
import feedparser
import requests
from datetime import datetime, date
from urllib.parse import urlencode, quote_plus
from dotenv import load_dotenv
from llama_index.core import (
    VectorStoreIndex, SimpleDirectoryReader,
    StorageContext, load_index_from_storage, Settings
)
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
import logging, traceback
from io import BytesIO
from PIL import Image

# â”€â”€â”€ í™˜ê²½ë³€ìˆ˜ & API í‚¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
openai.api_key = (
    st.secrets.get("OPENAI_API_KEY")
    or os.getenv("OPENAI_API_KEY", "")
)
API_KEY      = os.getenv("ODCLOUD_API_KEY")      # ì„ ë°• ê´€ì œ API
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
HF_API_URL   = os.getenv("HF_API_URL")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Google News RSS  +  ë§í¬ ì¼ê´„ ë³µì‚¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=300)
def fetch_google_news(keyword: str, max_items: int = 10):
    clean_kw = " ".join(keyword.strip().split())
    params   = {"q": clean_kw, "hl": "ko", "gl": "KR", "ceid": "KR:ko"}
    rss_url  = "https://news.google.com/rss/search?" + urlencode(params, doseq=True)
    feed     = feedparser.parse(rss_url)
    items    = []
    for entry in feed.entries[:max_items]:
        pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        source   = entry.get("source", {}).get("title", "")
        items.append({
            "title":  entry.title,
            "link":   entry.link,
            "source": source,
            "date":   pub_date,
        })
    return items

def google_news_section():
    st.subheader("ğŸ“° Google News ê²€ìƒ‰")
    kw        = st.text_input("í‚¤ì›Œë“œ", value="ì¹´ì¹´ì˜¤")
    max_items = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ê°œìˆ˜", 5, 100, 10)
    if st.button("ë³´ê¸°", key="news_search_btn"):
        news = fetch_google_news(kw, max_items)
        if not news:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # â‘  ê²°ê³¼ ëª©ë¡
        for item in news:
            st.markdown(
                f"- **[{item['source']}] Â· {item['date']}** "
                f"[{item['title']}]({item['link']})",
                unsafe_allow_html=True
            )

        # â‘¡ ë§í¬ ì¼ê´„ ë³µì‚¬ìš© ë¬¸ìì—´
        links_str = "\n".join([n["link"] for n in news])
        st.text_area("ğŸ”— ë§í¬ ì¼ê´„ ë³µì‚¬ìš©", links_str, height=100)

        # â‘¢ copy-to-clipboard ë²„íŠ¼ (JS)
        btn_html = f"""
        <button id="copy-btn"
                style="margin-top:6px;padding:6px 12px;background:#f44336;
                       color:white;border:none;border-radius:4px;cursor:pointer;"
                onclick="navigator.clipboard.writeText(`{links_str}`);
                         const t=this.innerText; this.innerText='âœ… ë³µì‚¬ ì™„ë£Œ!';
                         setTimeout(()=>this.innerText=t,1500);">
            ğŸ“‹ {len(news)}ê°œ ë§í¬ ë³µì‚¬
        </button>
        """
        st.markdown(btn_html, unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œ ì •ë³´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vessel_monitoring_section():
    st.subheader("ğŸš¢ í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ")
    date_from = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", date.today())
    date_to   = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", date.today())
    page      = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", 1, 1000, 1)
    per_page  = st.slider("í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê±´ìˆ˜", 1, 1000, 100)
    if st.button("ğŸ” ì¡°íšŒ", key="vessel_btn"):
        params = {
            "serviceKey": API_KEY,
            "page":       page,
            "perPage":    per_page,
            "fromDate":   date_from.strftime("%Y-%m-%d"),
            "toDate":     date_to.strftime("%Y-%m-%d"),
        }
        with st.spinner("ì¡°íšŒ ì¤‘â€¦"):
            res = requests.get(
                "https://api.odcloud.kr/api/15128156/v1/uddi:fdcdb0d1-0296-4c3b-8087-8ab4bd4d5123",
                params=params
            )
        if res.status_code != 200:
            st.error(f"API ì˜¤ë¥˜ {res.status_code}")
            return
        data = res.json().get("data", [])
        if data:
            df = pd.DataFrame(data)
            st.success(f"ì´ {len(df)} ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ì˜¤ëŠ˜ì˜ ë‚ ì”¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def today_weather_section():
    st.subheader("â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì¡°íšŒ")
    city_name = st.text_input("ë„ì‹œ ì´ë¦„ ì…ë ¥ (ì˜ˆ: ì¸ì²œ, Busan)")
    if st.button("ğŸ” ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°", key="weather_btn"):
        if not city_name:
            st.warning("ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return

        q_name  = quote_plus(city_name)
        geo_url = f"https://geocoding-api.open-meteo.com/v1/search?name={q_name}&count=5&language=ko"
        with st.spinner("ìœ„ì¹˜ ê²€ìƒ‰ ì¤‘â€¦"):
            geo_res = requests.get(geo_url)
        if geo_res.status_code != 200:
            st.error("ì§€ì˜¤ì½”ë”© API ì˜¤ë¥˜")
            return
        results = geo_res.json().get("results")
        if not results:
            st.warning("ë„ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        loc          = results[0]
        lat, lon     = loc["latitude"], loc["longitude"]
        display_name = f"{loc['name']}, {loc['country']}"

        weather_url = (
            f"https://api.open-meteo.com/v1/forecast?"
            f"latitude={lat}&longitude={lon}&current_weather=true"
            f"&hourly=relativehumidity_2m&timezone=auto"
        )
        with st.spinner(f"{display_name} ë‚ ì”¨ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            w_res = requests.get(weather_url)
        if w_res.status_code != 200:
            st.error("ë‚ ì”¨ API ì˜¤ë¥˜")
            return

        js   = w_res.json()
        cw   = js.get("current_weather", {})
        temp, wind_spd, wind_dir, code = (
            cw.get("temperature"),
            cw.get("windspeed"),
            cw.get("winddirection"),
            cw.get("weathercode"),
        )
        wc_map = {
            0:"ë§‘ìŒ",1:"ì£¼ë¡œ ë§‘ìŒ",2:"ë¶€ë¶„ì  êµ¬ë¦„",3:"êµ¬ë¦„ ë§ìŒ",
            45:"ì•ˆê°œ",48:"ì•ˆê°œ(ì…ìƒ)",
            51:"ì´ìŠ¬ë¹„ ì•½í•¨",53:"ì´ìŠ¬ë¹„ ë³´í†µ",55:"ì´ìŠ¬ë¹„ ê°•í•¨",
            61:"ë¹—ë°©ìš¸ ì•½í•¨",63:"ë¹—ë°©ìš¸ ë³´í†µ",65:"ë¹—ë°©ìš¸ ê°•í•¨",
            80:"ì†Œë‚˜ê¸° ì•½í•¨",81:"ì†Œë‚˜ê¸° ë³´í†µ",82:"ì†Œë‚˜ê¸° ê°•í•¨",
            95:"ë‡Œìš°",96:"ì•½í•œ ë‡Œìš°",99:"ê°•í•œ ë‡Œìš°"
        }
        desc      = wc_map.get(code, "ì•Œ ìˆ˜ ì—†ìŒ")
        times     = js["hourly"]["time"]
        hums      = js["hourly"]["relativehumidity_2m"]
        now       = datetime.now().strftime("%Y-%m-%dT%H:00")
        humidity  = hums[times.index(now)] if now in times else None

        st.markdown(f"### {display_name} í˜„ì¬ ë‚ ì”¨")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ ê¸°ì˜¨(â„ƒ)", temp)
        c2.metric("ğŸ’¨ í’ì†(m/s)", wind_spd)
        c3.metric("ğŸŒ«ï¸ í’í–¥(Â°)", wind_dir)
        c4.metric("ğŸ’§ ìŠµë„(%)", humidity or "â€“")
        st.markdown(f"**ë‚ ì”¨ ìƒíƒœ:** {desc}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) Chatbot (Vision)  â€•  ì…ë ¥ ë©”ì‹œì§€ëŠ” ëª¨ë‘ í™”ë©´ì— ìœ ì§€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
enc = tiktoken.encoding_for_model("gpt-4o")
MAX_TOKENS        = 262_144
SUMMARY_THRESHOLD = 40
KEEP_RECENT       = 10

def num_tokens(messages: list) -> int:
    total = 0
    for m in messages:
        c = m["content"]
        if isinstance(c, list):
            for blk in c:
                total += len(enc.encode(
                    blk["text"] if blk["type"] == "text" else blk["image_url"]["url"]
                ))
        else:
            total += len(enc.encode(c))
    return total

@backoff.on_exception(backoff.expo, openai.RateLimitError, max_time=60, jitter=None)
def safe_chat_completion(messages, model="gpt-4o"):
    if num_tokens(messages) > MAX_TOKENS:
        raise ValueError("ì…ë ¥ í† í° ì´ˆê³¼")
    return openai.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=300,
        stream=True
    )

def compress_image(file, max_px=768, quality=85):
    img = Image.open(file)
    if max(img.size) > max_px:
        r = max_px / max(img.size)
        img = img.resize((int(img.width*r), int(img.height*r)), Image.LANCZOS)
    buf = BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=quality)
    return buf.getvalue()

def summarize_history(history: list) -> str:
    prompt = [{"role":"system","content":"ì•„ë˜ ëŒ€í™”ë¥¼ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."}]
    prompt += history + [{"role":"user","content":"ì, ì´ ëŒ€í™” ë‚´ìš©ì„ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì¤˜."}]
    res = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=prompt,
        max_tokens=200
    )
    return res.choices[0].message.content.strip()

def chatgpt_clone_section():
    st.subheader("ğŸ’¬ Chatbot (Vision)")

    # ì„¸ì…˜ ìƒíƒœ
    st.session_state.setdefault("chat_history",  [])  # UI ì „ìš©
    st.session_state.setdefault("model_history", [])  # GPT í˜¸ì¶œìš©

    img_file = st.file_uploader("ğŸ–¼ï¸ ì´ë¯¸ì§€ (ì„ íƒ)", type=["png", "jpg", "jpeg"])
    prompt   = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    # 1) model_history ìš”ì•½(í† í° ê°ì¶•)
    if len(st.session_state.model_history) > SUMMARY_THRESHOLD:
        try:
            summary_txt = summarize_history(st.session_state.model_history)
            recent = st.session_state.model_history[-KEEP_RECENT:]
            st.session_state.model_history = [{"role":"assistant","content":summary_txt}] + recent
        except Exception as e:
            st.error(f"ëŒ€í™” ìš”ì•½ ì˜¤ë¥˜: {e}")

    # 2) ì´ì „ ëŒ€í™” í‘œì‹œ
    for msg in st.session_state.chat_history:
        role, content = msg["role"], msg["content"]
        with st.chat_message("user" if role=="user" else "assistant"):
            if isinstance(content, list):
                for blk in content:
                    if blk["type"] == "text":
                        st.write(blk["text"])
                    else:
                        st.image(blk["image_url"]["url"], caption="ì—…ë¡œë“œ ì´ë¯¸ì§€")
            else:
                st.write(content)

    # 3) ì…ë ¥ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if img_file is None and not prompt:
        return

    # 4) ì‚¬ìš©ì ë¸”ë¡ êµ¬ì„±
    user_blocks = []
    if prompt:
        user_blocks.append({"type":"text","text":prompt})
    if img_file:
        jpg_bytes = compress_image(img_file)
        st.image(jpg_bytes,
                 caption=f"ë¯¸ë¦¬ë³´ê¸° ({len(jpg_bytes)//1024} KB)",
                 use_container_width=True)
        b64 = base64.b64encode(jpg_bytes).decode()
        user_blocks.append({
            "type":"image_url",
            "image_url":{"url":f"data:image/jpeg;base64,{b64}"}
        })

    # 5) íˆìŠ¤í† ë¦¬ ì¶”ê°€
    st.session_state.chat_history.append({"role":"user","content":user_blocks})
    st.session_state.model_history.append({"role":"user","content":user_blocks})

    # 6) GPT í˜¸ì¶œ
    try:
        resp = safe_chat_completion(st.session_state.model_history)
        buf = ""
        st.session_state.chat_history.append({"role":"assistant","content":""})
        st.session_state.model_history.append({"role":"assistant","content":""})
        with st.chat_message("assistant"):
            ph = st.empty()
            for chunk in resp:
                delta = chunk.choices[0].delta.content
                if delta:
                    buf += delta
                    ph.markdown(buf + "â–Œ")
            ph.markdown(buf)
        st.session_state.chat_history[-1]["content"] = buf
        st.session_state.model_history[-1]["content"] = buf
    except openai.RateLimitError:
        st.error("â³ ë ˆì´íŠ¸ ë¦¬ë°‹, ì ì‹œ í›„ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"OpenAI í˜¸ì¶œ ì˜¤ë¥˜: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) ëŒ“ê¸€  (comments.csv)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def comments_section():
    st.subheader("ğŸ—¨ï¸ ëŒ“ê¸€ ë‚¨ê¸°ê¸°")
    comments_file = "comments.csv"
    if not os.path.exists(comments_file):
        pd.DataFrame(columns=["timestamp","name","comment"])\
            .to_csv(comments_file, index=False, encoding="utf-8-sig")

    with st.form(key="comment_form", clear_on_submit=True):
        name    = st.text_input("ì´ë¦„", max_chars=50)



















