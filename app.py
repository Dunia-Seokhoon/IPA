import os
import streamlit as st
import streamlit.components.v1 as components
import openai
import base64
import backoff
import tiktoken
import time
import pandas as pd
import matplotlib.pyplot as plt
import feedparser
import requests
from datetime import datetime, date
from urllib.parse import urlencode, quote_plus
from dotenv import load_dotenv
from llama_index.core import (
    VectorStoreIndex, SimpleDirectoryReader,
    StorageContext, load_index_from_storage, Settings
)
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
import logging, traceback
from io import BytesIO
from PIL import Image

load_dotenv()

# â”€â”€â”€ API í‚¤ë“¤ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai.api_key = (
    st.secrets.get("OPENAI_API_KEY")
    or os.getenv("OPENAI_API_KEY", "")
)
API_KEY      = os.getenv("ODCLOUD_API_KEY")
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
HF_API_URL   = os.getenv("HF_API_URL")

# â”€â”€â”€ 1) ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ (Google News RSS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=300)
def fetch_google_news(keyword: str, max_items: int = 10):
    clean_kw = " ".join(keyword.strip().split())
    params   = {"q": clean_kw, "hl": "ko", "gl": "KR", "ceid": "KR:ko"}
    rss_url  = "https://news.google.com/rss/search?" + urlencode(params, doseq=True)
    feed     = feedparser.parse(rss_url)
    items    = []
    for entry in feed.entries[:max_items]:
        pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        source   = entry.get("source", {}).get("title", "")
        items.append({
            "title":  entry.title,
            "link":   entry.link,
            "source": source,
            "date":   pub_date,
        })
    return items


# â”€â”€â”€ 1-A) UI ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def google_news_section():
    st.subheader("ğŸ“° Google News ê²€ìƒ‰")
    kw        = st.text_input("í‚¤ì›Œë“œ", value="ê¸€ë¡œë²Œ ESG í˜„í™© ")
    max_items = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ê°œìˆ˜", 5, 100, 10)
    if st.button("ë³´ê¸°"):
        news = fetch_google_news(kw, max_items)
        if not news:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # â‘  ê²°ê³¼ ëª©ë¡ ì¶œë ¥
        for item in news:
            st.markdown(
                f"- **[{item['source']}] Â· {item['date']}** "
                f"[{item['title']}]({item['link']})",
                unsafe_allow_html=True
            )

        # â‘¡ ë§í¬ ë¬¸ìì—´ ìƒì„±
        links_str = "\n".join([n["link"] for n in news])

        # â‘¢ ë³µì‚¬ìš© í…ìŠ¤íŠ¸ ì˜ì—­ & JS ë²„íŠ¼
        st.text_area("ğŸ”— ë§í¬ ì¼ê´„ ë³µì‚¬ìš©", links_str, height=100)

        # copy-to-clipboard ë²„íŠ¼ (JS)
        btn_html = f"""
        <button id="copy-btn"
                style="margin-top:6px;padding:6px 12px;background:#f44336;
                       color:white;border:none;border-radius:4px;cursor:pointer;"
                onclick="navigator.clipboard.writeText(`{links_str}`); 
                         var t=this.innerText; this.innerText='âœ… ë³µì‚¬ ì™„ë£Œ!';
                         setTimeout(()=>this.innerText=t, 1500);">
            ğŸ“‹ {len(news)}ê°œ ë§í¬ ë³µì‚¬
        </button>
        """
        st.markdown(btn_html, unsafe_allow_html=True)


# â”€â”€â”€ 2) ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vessel_monitoring_section():
    st.subheader("ğŸš¢ í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ")
    date_from = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", date.today())
    date_to   = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", date.today())
    page      = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", 1, 1000, 1)
    per_page  = st.slider("í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê±´ìˆ˜", 1, 1000, 100)
    if st.button("ğŸ” ì¡°íšŒ"):
        params = {
            "serviceKey": API_KEY,
            "page":       page,
            "perPage":    per_page,
            "fromDate":   date_from.strftime("%Y-%m-%d"),
            "toDate":     date_to.strftime("%Y-%m-%d"),
        }
        with st.spinner("ì¡°íšŒ ì¤‘â€¦"):
            res = requests.get(
                "https://api.odcloud.kr/api/15128156/v1/uddi:fdcdb0d1-0296-4c3b-8087-8ab4bd4d5123",
                params=params
            )
        if res.status_code != 200:
            st.error(f"API ì˜¤ë¥˜ {res.status_code}")
            return
        data = res.json().get("data", [])
        if data:
            df = pd.DataFrame(data)
            st.success(f"ì´ {len(df)} ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€ 3) ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def today_weather_section():
    st.subheader("â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì¡°íšŒ")
    city_name = st.text_input("ë„ì‹œ ì´ë¦„ ì…ë ¥ (ì˜ˆ: ì¸ì²œ,ì¸ì²œê´‘ì—­ì‹œ, Busan)")
    if st.button("ğŸ” ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°"):
        if not city_name:
            st.warning("ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return

        q_name  = quote_plus(city_name)
        geo_url = f"https://geocoding-api.open-meteo.com/v1/search?name={q_name}&count=5&language=ko"
        with st.spinner("ìœ„ì¹˜ ê²€ìƒ‰ ì¤‘â€¦"):
            geo_res = requests.get(geo_url)
        if geo_res.status_code != 200:
            st.error("ì§€ì˜¤ì½”ë”© API ì˜¤ë¥˜")
            return
        results = geo_res.json().get("results")
        if not results:
            st.warning("ë„ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        loc          = results[0]
        lat, lon     = loc["latitude"], loc["longitude"]
        display_name = f"{loc['name']}, {loc['country']}"

        weather_url = (
            f"https://api.open-meteo.com/v1/forecast?"
            f"latitude={lat}&longitude={lon}&current_weather=true"
            f"&hourly=relativehumidity_2m&timezone=auto"
        )
        with st.spinner(f"{display_name} ë‚ ì”¨ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            w_res = requests.get(weather_url)
        if w_res.status_code != 200:
            st.error("ë‚ ì”¨ API ì˜¤ë¥˜")
            return

        js   = w_res.json()
        cw   = js.get("current_weather", {})
        temp, wind_spd, wind_dir, code = (
            cw.get("temperature"),
            cw.get("windspeed"),
            cw.get("winddirection"),
            cw.get("weathercode"),
        )
        wc_map = {
            0:"ë§‘ìŒ",1:"ì£¼ë¡œ ë§‘ìŒ",2:"ë¶€ë¶„ì  êµ¬ë¦„",3:"êµ¬ë¦„ ë§ìŒ",
            45:"ì•ˆê°œ",48:"ì•ˆê°œ(ì…ìƒ)",
            51:"ì´ìŠ¬ë¹„ ì•½í•¨",53:"ì´ìŠ¬ë¹„ ë³´í†µ",55:"ì´ìŠ¬ë¹„ ê°•í•¨",
            61:"ë¹—ë°©ìš¸ ì•½í•¨",63:"ë¹—ë°©ìš¸ ë³´í†µ",65:"ë¹—ë°©ìš¸ ê°•í•¨",
            80:"ì†Œë‚˜ê¸° ì•½í•¨",81:"ì†Œë‚˜ê¸° ë³´í†µ",82:"ì†Œë‚˜ê¸° ê°•í•¨",
            95:"ë‡Œìš°",96:"ì•½í•œ ë‡Œìš°",99:"ê°•í•œ ë‡Œìš°"
        }
        desc      = wc_map.get(code, "ì•Œ ìˆ˜ ì—†ìŒ")
        times     = js["hourly"]["time"]
        hums      = js["hourly"]["relativehumidity_2m"]
        now       = datetime.now().strftime("%Y-%m-%dT%H:00")
        humidity  = hums[times.index(now)] if now in times else None

        st.markdown(f"### {display_name} í˜„ì¬ ë‚ ì”¨")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ ê¸°ì˜¨(â„ƒ)", temp)
        c2.metric("ğŸ’¨ í’ì†(m/s)", wind_spd)
        c3.metric("ğŸŒ«ï¸ í’í–¥(Â°)", wind_dir)
        c4.metric("ğŸ’§ ìŠµë„(%)", humidity or "â€“")
        st.markdown(f"**ë‚ ì”¨ ìƒíƒœ:** {desc}")


# â”€â”€â”€ 4) Chatbot (Vision) & ìš”ì•½ ê¸°ëŠ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
enc = tiktoken.encoding_for_model("gpt-4o")
MAX_TOKENS        = 262_144        # gpt-4o í—ˆìš©ì¹˜
SUMMARY_THRESHOLD = 40             # ìš”ì•½ íŠ¸ë¦¬ê±° í„´ ìˆ˜
KEEP_RECENT       = 10             # ìš”ì•½ í›„ ë‚¨ê²¨ë‘˜ ìµœì‹  ë©”ì‹œì§€ ìˆ˜

def num_tokens(messages: list) -> int:
    total = 0
    for m in messages:
        c = m["content"]
        if isinstance(c, list):
            for blk in c:
                total += len(enc.encode(
                    blk["text"] if blk["type"] == "text" else blk["image_url"]["url"]
                ))
        else:
            total += len(enc.encode(c))
    return total

@backoff.on_exception(backoff.expo, openai.RateLimitError, max_time=60, jitter=None)
def safe_chat_completion(messages, model="gpt-4o"):
    tk_in = num_tokens(messages)
    if tk_in > MAX_TOKENS:
        raise ValueError(f"ì…ë ¥ í† í° {tk_in}ê°œ â†’ ìµœëŒ€ í—ˆìš©ì¹˜({MAX_TOKENS}) ì´ˆê³¼ì…ë‹ˆë‹¤.")
    return openai.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=300,
        stream=True
    )

def compress_image(file, max_px=768, quality=85):
    img = Image.open(file)
    if max(img.size) > max_px:
        r = max_px / max(img.size)
        img = img.resize((int(img.width*r), int(img.height*r)), Image.LANCZOS)
    buf = BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=quality)
    return buf.getvalue()

def summarize_history(history: list) -> str:
    system_prompt = [{"role":"system","content":"ì•„ë˜ ëŒ€í™”ë¥¼ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."}]
    prompt = system_prompt + history + \
        [{"role":"user","content":"ì, ì´ ëŒ€í™” ë‚´ìš©ì„ 3ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ ì¤˜."}]
    res = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=prompt,
        max_tokens=200
    )
    return res.choices[0].message.content.strip()

def chatgpt_clone_section():
    st.subheader("ğŸ’¬ Chatbot (Vision)")

    # â”€â”€ ìƒíƒœ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.session_state.setdefault("chat_history",  [])  # UI í‘œì‹œìš©(ëª¨ë‘ ì €ì¥)
    st.session_state.setdefault("model_history", [])  # ëª¨ë¸ í˜¸ì¶œìš©(ìš”ì•½ ê°€ëŠ¥)

    img_file = st.file_uploader("ğŸ–¼ï¸ ì´ë¯¸ì§€ (ì„ íƒ)", type=["png", "jpg", "jpeg"])
    prompt   = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    # â”€â”€ 1) í•„ìš” ì‹œ model_history ìš”ì•½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if len(st.session_state.model_history) > SUMMARY_THRESHOLD:
        try:
            summary_txt = summarize_history(st.session_state.model_history)
            recent      = st.session_state.model_history[-KEEP_RECENT:]
            st.session_state.model_history = \
                [{"role":"assistant","content":summary_txt}] + recent
        except Exception as e:
            st.error(f"ëŒ€í™” ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # â”€â”€ 2) ì´ì „ ëŒ€í™” í™”ë©´ í‘œì‹œ(chat_history ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for msg in st.session_state.chat_history:
        role, content = msg["role"], msg["content"]
        with st.chat_message("user" if role=="user" else "assistant"):
            if isinstance(content, list):               # ë©€í‹°ë¸”ë¡(user)
                for blk in content:
                    if blk["type"] == "text":
                        st.write(blk["text"])
                    else:
                        st.image(blk["image_url"]["url"],
                                 caption="ì—…ë¡œë“œ ì´ë¯¸ì§€")
            else:                                       # ë‹¨ì¼ í…ìŠ¤íŠ¸
                st.write(content)

    # â”€â”€ 3) ì…ë ¥ ì—†ìœ¼ë©´ ì¢…ë£Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if img_file is None and not prompt:
        return

    # â”€â”€ 4) ì‚¬ìš©ì ì…ë ¥ ë¸”ë¡ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    user_blocks = []
    if prompt:
        user_blocks.append({"type":"text","text":prompt})
    if img_file:
        jpg_bytes = compress_image(img_file)
        st.image(jpg_bytes,
                 caption=f"ë¯¸ë¦¬ë³´ê¸° ({len(jpg_bytes)//1024} KB)",
                 use_container_width=True)
        b64 = base64.b64encode(jpg_bytes).decode()
        user_blocks.append({
            "type":"image_url",
            "image_url":{"url":f"data:image/jpeg;base64,{b64}"}
        })

    # â”€â”€ 5) ë‘ íˆìŠ¤í† ë¦¬ì— ëª¨ë‘ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.session_state.chat_history.append({"role":"user", "content":user_blocks})
    st.session_state.model_history.append({"role":"user","content":user_blocks})

    # â”€â”€ 6) í† í° ì²´í¬ & GPT í˜¸ì¶œ(model_history ì‚¬ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if num_tokens(st.session_state.model_history) > MAX_TOKENS:
        st.error("âš ï¸ í† í° í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì˜¤ë˜ëœ ëŒ€í™”ë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ìƒˆ ì°½ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”.")
        return

    try:
        resp = safe_chat_completion(st.session_state.model_history)
        buf  = ""
        # ë¯¸ë¦¬ ë¹„ì–´ ìˆëŠ” assistant ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role":"assistant","content":""})
        st.session_state.model_history.append({"role":"assistant","content":""})

        with st.chat_message("assistant"):
            ph = st.empty()
            for chunk in resp:
                delta = chunk.choices[0].delta.content
                if delta:
                    buf += delta
                    ph.markdown(buf + "â–Œ")   # ìŠ¤íŠ¸ë¦¬ë° ì¤‘
            ph.markdown(buf)

        # ë‘ íˆìŠ¤í† ë¦¬ì— ìµœì¢… ë‹µë³€ ë°˜ì˜
        st.session_state.chat_history[-1]["content"] = buf
        st.session_state.model_history[-1]["content"] = buf

    except openai.RateLimitError:
        st.error("â³ ë ˆì´íŠ¸ ë¦¬ë°‹ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
    except Exception as e:
        st.error(f"OpenAI í˜¸ì¶œ ì˜¤ë¥˜: {e}")


# â”€â”€â”€ 5) ëŒ“ê¸€ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def comments_section():
    """
    ë¡œì»¬ CSV íŒŒì¼(comments.csv)ì„ ì‚¬ìš©í•˜ì—¬ ëŒ“ê¸€ì„ ì €ì¥í•˜ê³ , ë³´ì—¬ì£¼ëŠ” ì„¹ì…˜.
    """
    st.subheader("ğŸ—¨ï¸ ëŒ“ê¸€ ë‚¨ê¸°ê¸°")

    # 1) ëŒ“ê¸€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    comments_file = "comments.csv"

    # 2) ëŒ“ê¸€ì„ ì €ì¥í•  CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ë§Œ ìƒì„±
    if not os.path.exists(comments_file):
        df_init = pd.DataFrame(columns=["timestamp", "name", "comment"])
        df_init.to_csv(comments_file, index=False, encoding="utf-8-sig")

    # 3) ëŒ“ê¸€ì„ ì…ë ¥ë°›ì„ UI (ì´ë¦„, ëŒ“ê¸€ ë‚´ìš©, ë“±ë¡ ë²„íŠ¼)
    with st.form(key="comment_form", clear_on_submit=True):
        name = st.text_input("ì´ë¦„", max_chars=50)
        comment = st.text_area("ëŒ“ê¸€ ë‚´ìš©", height=100, max_chars=500)
        submitted = st.form_submit_button("ë“±ë¡")

    # 4) ì‚¬ìš©ìê°€ ì œì¶œ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ CSVì— ì €ì¥
    if submitted:
        if not name.strip():
            st.warning("ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif not comment.strip():
            st.warning("ëŒ“ê¸€ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
            ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            # ìƒˆë¡œìš´ ëŒ“ê¸€ DataFrame
            new_row = pd.DataFrame([{
                "timestamp": ts,
                "name": name.strip(),
                "comment": comment.strip()
            }])
            # CSVì— ì´ì–´ë¶™ì´ê¸°
            new_row.to_csv(comments_file, mode="a", header=False, index=False, encoding="utf-8-sig")
            st.success("ëŒ“ê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # 5) ì €ì¥ëœ ëª¨ë“  ëŒ“ê¸€ì„ ì½ì–´ì„œ í™”ë©´ì— í‘œì‹œ
    try:
        all_comments = pd.read_csv(comments_file, encoding="utf-8-sig")
        # ìµœì‹ ìˆœìœ¼ë¡œ í‘œì‹œí•˜ë ¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì •ë ¬
        all_comments = all_comments.sort_values(by="timestamp", ascending=False)
        st.markdown("#### ì „ì²´ ëŒ“ê¸€")
        for _, row in all_comments.iterrows():
            st.markdown(f"- **[{row['timestamp']}] {row['name']}**: {row['comment']}")
    except Exception as e:
        st.error(f"ëŒ“ê¸€ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# â”€â”€â”€ 6) â€œESG í™œë™ ì°¸ì—¬â€ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def participation_section():
    st.subheader("ğŸ–Šï¸ ESG í™œë™ ì°¸ì—¬")
    img_dir  = "participation_images"
    csv_file = "participation.csv"

    # â”€â”€ 1) ë””ë ‰í„°ë¦¬Â·CSV ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not os.path.exists(img_dir):
        os.makedirs(img_dir)
    if not os.path.exists(csv_file):
        pd.DataFrame(columns=["timestamp", "department", "name",
                              "image_filename"]).to_csv(csv_file,
                                                        index=False,
                                                        encoding="utf-8-sig")

    # â”€â”€ 2) ì‹ ê·œ ë“±ë¡ í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.form(key="participation_form", clear_on_submit=True):
        dept          = st.text_input("ì°¸ì—¬ ë¶€ì„œ", max_chars=50)
        person        = st.text_input("ì„±ëª…",       max_chars=30)
        uploaded_file = st.file_uploader("ì¦ëª…ìë£Œ(ì´ë¯¸ì§€)",
                                         type=["png", "jpg", "jpeg"])
        submit_button = st.form_submit_button("ì œì¶œ")

    if submit_button:
        if not dept.strip():
            st.warning("ì°¸ì—¬ ë¶€ì„œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif not person.strip():
            st.warning("ì„±ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        elif uploaded_file is None:
            st.warning("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        else:
            ts         = datetime.now().strftime("%Y%m%d_%H%M%S")
            ext        = os.path.splitext(uploaded_file.name)[1].lower()
            safe_name  = "".join(person.split())
            img_fname  = f"{ts}_{safe_name}{ext}"
            img_path   = os.path.join(img_dir, img_fname)

            with open(img_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            pd.DataFrame([{
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "department": dept.strip(),
                "name": person.strip(),
                "image_filename": img_fname
            }]).to_csv(csv_file, mode="a", header=False, index=False,
                       encoding="utf-8-sig")
            st.success("âœ… ì°¸ì—¬ ì •ë³´ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # â”€â”€ 3) ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        all_data = pd.read_csv(csv_file, encoding="utf-8-sig")\
                     .sort_values(by="timestamp", ascending=False)

        # 3-1) CSV ë‹¤ìš´ë¡œë“œ ë§í¬
        def get_table_download_link(df, filename="participation.csv"):
            csv = df.to_csv(index=False, encoding="utf-8-sig")
            b64 = base64.b64encode(csv.encode()).decode()
            return f'<a href="data:file/csv;base64,{b64}" download="{filename}">ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ</a>'
        st.markdown(get_table_download_link(all_data), unsafe_allow_html=True)

        # 3-2) í‘œ í‘œì‹œ
        st.dataframe(all_data, use_container_width=True)

        # 3-3) ìˆ˜ì • êµ¬ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with st.expander("âœï¸ ë°ì´í„° ìˆ˜ì •", expanded=False):
            if all_data.empty:
                st.info("ìˆ˜ì •í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                row_idx = st.selectbox(
                    "ìˆ˜ì •í•  í•­ëª© ì„ íƒ",
                    all_data.index,
                    format_func=lambda i: f"{all_data.loc[i,'timestamp']} / {all_data.loc[i,'name']}"
                )
                if row_idx is not None:
                    # í˜„ì¬ ê°’ í‘œì‹œ
                    new_dept = st.text_input("ë¶€ì„œ", value=all_data.loc[row_idx, "department"], key="edit_dept")
                    new_name = st.text_input("ì„±ëª…", value=all_data.loc[row_idx, "name"],       key="edit_name")
                    new_img  = st.file_uploader("ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ(ì„ íƒ)", type=["png","jpg","jpeg"], key="edit_img")

                    if st.button("ì €ì¥", key="save_edit"):
                        # ì´ë¯¸ì§€ êµì²´(ì„ íƒ)
                        img_fname = all_data.loc[row_idx, "image_filename"]
                        if new_img is not None:
                            # ê¸°ì¡´ íŒŒì¼ ì œê±°
                            old_path = os.path.join(img_dir, img_fname)
                            if os.path.exists(old_path):
                                os.remove(old_path)

                            ext = os.path.splitext(new_img.name)[1].lower()
                            img_fname = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{''.join(new_name.split())}{ext}"
                            with open(os.path.join(img_dir, img_fname), "wb") as f:
                                f.write(new_img.getbuffer())

                        # DataFrame ê°±ì‹ 
                        all_data.loc[row_idx, ["department","name","image_filename"]] = \
                            [new_dept.strip(), new_name.strip(), img_fname]
                        all_data.to_csv(csv_file, index=False, encoding="utf-8-sig")
                        st.success("âœ… ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.experimental_rerun()

        # 3-4) ì‚­ì œ êµ¬ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with st.expander("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ", expanded=False):
            if all_data.empty:
                st.info("ì‚­ì œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                del_rows = st.multiselect(
                    "ì‚­ì œí•  í•­ëª© ì„ íƒ(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
                    all_data.index,
                    format_func=lambda i: f"{all_data.loc[i,'timestamp']} / {all_data.loc[i,'name']}"
                )
                if st.button("ì‚­ì œ", key="delete_rows") and del_rows:
                    # ì„ íƒ í–‰ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
                    for idx in del_rows:
                        img_path = os.path.join(img_dir, all_data.loc[idx, "image_filename"])
                        if os.path.exists(img_path):
                            os.remove(img_path)
                    # DataFrame ê°±ì‹ 
                    all_data = all_data.drop(del_rows).reset_index(drop=True)
                    all_data.to_csv(csv_file, index=False, encoding="utf-8-sig")
                    st.success("ğŸ—‘ï¸ ì„ íƒí•œ í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.experimental_rerun()

        # 3-5) ì¸ë„¤ì¼ ì¶œë ¥
        for _, row in all_data.iterrows():
            col1, col2 = st.columns([1,3])
            with col1:
                path = os.path.join(img_dir, row["image_filename"])
                st.image(path if os.path.exists(path) else None, width=80, caption=row["name"])
            with col2:
                st.write(f"- **[{row['timestamp']}]** {row['department']} / {row['name']}")

    except Exception as e:
        st.error(f"ì°¸ì—¬ í˜„í™©ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# â”€â”€â”€ 7) ì˜ìƒ ëª¨ìŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def video_collection_section():
    st.subheader("ğŸ“º ESG ì˜ìƒ ëª¨ìŒ")
    # 1. ì‚¬ë¬´ì‹¤ì—ì„œ ì´ë©´ì§€ í™œìš©í•˜ê¸°!
    st.markdown("#### ì‚¬ë¬´ì‹¤ì—ì„œ ì´ë©´ì§€ í™œìš©í•˜ê¸°!")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%82%AC%EB%AC%B4%EC%8B%A4%EC%97%90%EC%84%9C%20%EC%9D%B4%EB%A9%B4%EC%A7%80%20%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0.mp4")
    st.write("")  # ì¤„ ê°„ê²©

    # 2. ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 1íƒ„
    st.markdown("#### ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 1íƒ„")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%B9%B4%ED%8E%98%EC%97%90%EC%84%9C%20%ED%85%80%EB%B8%94%EB%9F%AC%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0.mp4")
    st.write("")

    # 3. ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 2íƒ„
    st.markdown("#### ì¹´í˜ì—ì„œ ESG ì‹¤ì²œí•˜ê¸° 2íƒ„")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%B9%B4%ED%8E%98%EC%97%90%EC%84%9C%20%ED%9C%B4%EC%A7%80%20%EC%A0%81%EA%B2%8C%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0.mp4")

    # 4. íšŒì˜ì‹¤ì—ì„œ ë¶ˆ ë„ê¸° 
    st.markdown("#### íšŒì˜ì‹¤ì—ì„œ ë¶ˆ ë„ê¸°")
    st.video("https://storage.googleapis.com/videoupload_icpa/%ED%9A%8C%EC%9D%98%EC%8B%A4%EC%97%90%EC%84%9C%20%EB%B6%88%EB%81%84%EA%B8%B0.mp4")

    # 5.ì¼íšŒìš©í’ˆ ì‚¬ìš© ì¤„ì´ê¸°
    st.markdown("#### ì¼íšŒìš©í’ˆ ì‚¬ìš© ì¤„ì´ê¸°")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EC%9D%BC%ED%9A%8C%EC%9A%A9%ED%92%88%20%EC%82%AC%EC%9A%A9%20%EC%A4%84%EC%9D%B4%EA%B8%B0.mp4")
    
    # 5.ë¶„ë¦¬ìˆ˜ê±°ì¥ì—ì„œ ESG ì‹¤ì²œí•˜ê¸°
    st.markdown("#### ë¶„ë¦¬ìˆ˜ê±°ì¥ì—ì„œ ESG ì‹¤ì²œí•˜ê¸°")
    st.video("https://storage.googleapis.com/videoupload_icpa/%EB%B6%84%EB%A6%AC%EC%88%98%EA%B1%B0%EC%9E%A5%EC%97%90%EC%84%9C%20%EC%8B%A4%EC%B2%9C%ED%95%98%EB%8A%94%20ESG%20.mp4")

    

# â”€â”€â”€ 8) ì•± ë ˆì´ì•„ì›ƒ (íƒ­ êµ¬ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ì¸ì²œí•­ë§Œê³µì‚¬ ESG í†µí•© í¬í„¸", layout="centered")
st.title("ğŸ“ˆ ì¸ì²œí•­ë§Œê³µì‚¬ ESG í†µí•© í¬í„¸: ë‰´ìŠ¤Â·ì„ ë°•Â·ë‚ ì”¨Â·ChatbotÂ·ëŒ“ê¸€Â·ESG í™œë™ ì°¸ì—¬Â·ESG ì˜ìƒ ëª¨ìŒ")

tabs = st.tabs([
    "êµ¬ê¸€ ë‰´ìŠ¤", "ì„ ë°• ê´€ì œì •ë³´", "ì˜¤ëŠ˜ì˜ ë‚ ì”¨", "Chatbot", "ëŒ“ê¸€", "ESG í™œë™ ì°¸ì—¬", "ESG ì˜ìƒ ëª¨ìŒ"
])

with tabs[0]:
    google_news_section()   # ğŸ‘ˆ ë”± í•œ ì¤„!

with tabs[1]:
    vessel_monitoring_section()

with tabs[2]:
    today_weather_section()

with tabs[3]:
    chatgpt_clone_section()

with tabs[4]:
    comments_section()

with tabs[5]:
    participation_section()

with tabs[6]:
    video_collection_section()














