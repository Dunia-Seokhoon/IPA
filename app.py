# app.py  |  Streamlit í†µí•© ë°ëª¨
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import feedparser
import requests
from datetime import datetime, date
from urllib.parse import urlencode

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•˜ë“œì½”ë”©ëœ API í‚¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = "GprdI3W07y8Ul7R0KwyRE0Beb1Y2wqtlBuvzWRqLqIZzEkR7xrPePc6CMQeD9FQAsTyQHh1V8NDK1md4ou4WGw=="

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ (Google News RSS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=300)
def fetch_google_news(keyword: str, max_items: int = 10):
    clean_kw = " ".join(keyword.strip().split())
    params = {"q": clean_kw, "hl": "ko", "gl": "KR", "ceid": "KR:ko"}
    rss_url = "https://news.google.com/rss/search?" + urlencode(params, doseq=True)
    feed = feedparser.parse(rss_url)

    items = []
    for entry in feed.entries[:max_items]:
        pub_date = datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
        source   = entry.get("source", {}).get("title", "")
        items.append({
            "title":  entry.title,
            "link":   entry.link,
            "source": source,
            "date":   pub_date,
        })
    return items

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) CSV íˆìŠ¤í† ê·¸ë¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def sample_data_section():
    st.subheader("ğŸ“Š ìƒ˜í”Œ ë°ì´í„° íˆìŠ¤í† ê·¸ë¨")
    uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ (optional)", type=["csv"])
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.dataframe(df)
        nums = df.select_dtypes(include="number").columns.tolist()
        if nums:
            col = st.selectbox("Numeric ì»¬ëŸ¼ ì„ íƒ", nums)
            fig, ax = plt.subplots()
            ax.hist(df[col], bins=10)
            ax.set_xlabel(col)
            ax.set_ylabel("Frequency")
            st.pyplot(fig)
    else:
        st.info("CSV íŒŒì¼ì„ ì˜¬ë¦¬ë©´ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°ì™€ íˆìŠ¤í† ê·¸ë¨ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ë™ì˜ìƒ ì—…ë¡œë“œÂ·ì¬ìƒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def video_upload_section():
    st.subheader("ğŸ“¹ ë™ì˜ìƒ ì—…ë¡œë“œ & ì¬ìƒ")
    video_file = st.file_uploader(
        "ë™ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ (MP4 / MOV / AVI)",
        type=["mp4", "mov", "avi"],
        key="video_uploader",
    )
    if video_file:
        st.video(video_file)
    else:
        st.info("ìœ„ ë²„íŠ¼ìœ¼ë¡œ ë™ì˜ìƒ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def vessel_monitoring_section():
    st.subheader("ğŸš¢ í•´ì–‘ìˆ˜ì‚°ë¶€ ì„ ë°• ê´€ì œì •ë³´ ì¡°íšŒ")

    date_from = st.date_input("ì¡°íšŒ ì‹œì‘ì¼", value=date.today())
    date_to   = st.date_input("ì¡°íšŒ ì¢…ë£Œì¼", value=date.today())
    page      = st.number_input("í˜ì´ì§€ ë²ˆí˜¸", min_value=1, value=1)
    per_page  = st.slider("í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê±´ìˆ˜", 1, 1000, 100)

    if st.button("ğŸ” ì¡°íšŒ", key="vessel_btn"):
        BASE_URL = (
            "https://api.odcloud.kr/api/15128156/v1/"
            "uddi:fdcdb0d1-0296-4c3b-8087-8ab4bd4d5123"
        )
        params = {
            "serviceKey": API_KEY,
            "page":       page,
            "perPage":    per_page,
            "fromDate":   date_from.strftime("%Y-%m-%d"),
            "toDate":     date_to.strftime("%Y-%m-%d"),
        }

        with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            try:
                res = requests.get(BASE_URL, params=params)
                res.raise_for_status()
                data = res.json()
            except Exception as e:
                st.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
                return

        if data.get("data"):
            df = pd.DataFrame(data["data"])
            total = data.get("totalCount", len(df))
            st.success(f"ì´ {total} ê±´ ì¡°íšŒë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.dataframe(df)
        else:
            st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown(
            """
            **ì°¸ê³ **  
            - API ëª…ì„¸: https://infuser.odcloud.kr/oas/docs?namespace=15128156/v1  
            """
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì„¹ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def today_weather_section():
    st.subheader("â˜€ï¸ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ ì¡°íšŒ")

    city = st.selectbox(
        "ë„ì‹œ ì„ íƒ",
        ["Seoul", "Busan", "Incheon"],
        format_func=lambda x: {"Seoul":"ì„œìš¸","Busan":"ë¶€ì‚°","Incheon":"ì¸ì²œ"}[x]
    )

    if st.button("ğŸ” ë‚ ì”¨ ê°€ì ¸ì˜¤ê¸°", key="weather_btn"):
        coords = {
            "Seoul":   (37.5665, 126.9780),
            "Busan":   (35.1796, 129.0756),
            "Incheon": (37.4563, 126.7052),
        }
        lat, lon = coords[city]

        url = (
            f"https://api.open-meteo.com/v1/forecast?"
            f"latitude={lat}&longitude={lon}"
            f"&current_weather=true"
            f"&hourly=relativehumidity_2m"
            f"&timezone=Asia/Seoul"
        )
        with st.spinner(f"{city} ë‚ ì”¨ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            res = requests.get(url)
            res.raise_for_status()
            js = res.json()

        # í˜„ì¬ ê¸°ìƒ ì •ë³´
        cw = js.get("current_weather", {})
        temp     = cw.get("temperature")
        wind_spd = cw.get("windspeed")
        wind_dir = cw.get("winddirection")
        code     = cw.get("weathercode")

        # ë‚ ì”¨ì½”ë“œ -> í…ìŠ¤íŠ¸
        wc_map = {
            0: "ë§‘ìŒ", 1: "ì£¼ë¡œ ë§‘ìŒ", 2: "ë¶€ë¶„ì  êµ¬ë¦„", 3: "êµ¬ë¦„ ë§ìŒ",
            45: "ì•ˆê°œ", 48: "ì•ˆê°œ(ì…ìƒ)",
            51: "ì´ìŠ¬ë¹„ ì•½í•¨", 53: "ì´ìŠ¬ë¹„ ë³´í†µ", 55: "ì´ìŠ¬ë¹„ ê°•í•¨",
            61: "ë¹—ë°©ìš¸ ì•½í•¨", 63: "ë¹—ë°©ìš¸ ë³´í†µ", 65: "ë¹—ë°©ìš¸ ê°•í•¨",
            80: "ì†Œë‚˜ê¸° ì•½í•¨", 81: "ì†Œë‚˜ê¸° ë³´í†µ", 82: "ì†Œë‚˜ê¸° ê°•í•¨",
            95: "ë‡Œìš°", 96: "ì•½í•œ ë‡Œìš°", 99: "ê°•í•œ ë‡Œìš°"
        }
        weather_desc = wc_map.get(code, "ì•Œ ìˆ˜ ì—†ìŒ")

        # í˜„ì¬ ìŠµë„
        times = js["hourly"]["time"]
        hums  = js["hourly"]["relativehumidity_2m"]
        now_str = datetime.now().strftime("%Y-%m-%dT%H:00")
        humidity = None
        if now_str in times:
            idx = times.index(now_str)
            humidity = hums[idx]

        # ì¶œë ¥
        st.markdown(f"### {city} í˜„ì¬ ë‚ ì”¨")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ ê¸°ì˜¨(â„ƒ)", temp)
        c2.metric("ğŸ’¨ í’ì†(m/s)", wind_spd)
        c3.metric("ğŸŒ«ï¸ í’í–¥(Â°)", wind_dir)
        c4.metric("ğŸ’§ ìŠµë„(%)", humidity if humidity is not None else "â€“")

        st.markdown(f"**ë‚ ì”¨ ìƒíƒœ:** {weather_desc}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6) ì•± ë ˆì´ì•„ì›ƒ (íƒ­ êµ¬ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="í†µí•© ë°ëª¨", layout="centered")
st.title("ğŸ“ˆ í†µí•© ë°ëª¨: ë‰´ìŠ¤ Â· ë°ì´í„° Â· ë™ì˜ìƒ Â· ì„ ë°• Â· ë‚ ì”¨")

tabs = st.tabs([
    "êµ¬ê¸€ ë‰´ìŠ¤", "ë°ì´í„° íˆìŠ¤í† ê·¸ë¨", "ë™ì˜ìƒ ì¬ìƒ",
    "ì„ ë°• ê´€ì œì •ë³´", "ì˜¤ëŠ˜ì˜ ë‚ ì”¨"
])

with tabs[0]:
    st.subheader("â–¶ êµ¬ê¸€ ë‰´ìŠ¤ í¬ë¡¤ë§ (RSS)")
    kw  = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", "ESG", key="kw_input")
    num = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ê°œìˆ˜", 5, 20, 10, key="num_slider")
    if st.button("ë³´ê¸°", key="news_btn"):
        with st.spinner(f"â€˜{kw}â€™ ë‰´ìŠ¤ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦"):
            for it in fetch_google_news(kw, num):
                st.markdown(f"- **[{it['source']} Â· {it['date']}]** [{it['title']}]({it['link']})")

with tabs[1]:
    sample_data_section()

with tabs[2]:
    video_upload_section()

with tabs[3]:
    vessel_monitoring_section()

with tabs[4]:
    today_weather_section()

